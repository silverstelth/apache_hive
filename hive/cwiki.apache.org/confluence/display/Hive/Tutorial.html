    

<!DOCTYPE html>
<html lang="en-GB" >

<!-- Mirrored from cwiki.apache.org/confluence/display/Hive/Tutorial by HTTrack Website Copier/3.x [XR&CO'2014], Wed, 15 Dec 2021 19:41:34 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=UTF-8" /><!-- /Added by HTTrack -->
<head>
                            <title>Tutorial - Apache Hive - Apache Software Foundation</title>
    
        

                        
    
                        
    

                
    
    <meta http-equiv="X-UA-Compatible" content="IE=EDGE,chrome=IE7">
<meta charset="UTF-8">
<meta id="confluence-context-path" name="confluence-context-path" content="/confluence">
<meta id="confluence-base-url" name="confluence-base-url" content="https://cwiki.apache.org/confluence">

    <meta id="atlassian-token" name="atlassian-token" content="d7833c7da397e2f88a76912a1879e0225325829d">


<meta id="confluence-space-key" name="confluence-space-key" content="Hive">
<script type="text/javascript">
        var contextPath = '/confluence';
</script>

    

    <meta name="confluence-request-time" content="1639597156431">
        
    
        
            <meta name="ajs-use-keyboard-shortcuts" content="true">
            <meta name="ajs-is-confluence-admin" content="false">
            <meta name="ajs-connection-timeout" content="10000">
            <script type="text/x-template" title="gliffy-webpanel-footer">
        <div class="gliffy-webpanel-footer"><span>This Confluence installation runs a Free Gliffy License - Evaluate the <a href="http://www.gliffy.com/products/confluence-plugin/">Gliffy Confluence Plugin</a> for your Wiki!</span></div>
</script>


            <style>.ia-fixed-sidebar, .ia-splitter-left {width: 285px;}.theme-default .ia-splitter #main {margin-left: 285px;}.ia-fixed-sidebar {visibility: hidden;}</style>
            <meta name="ajs-discovered-plugin-features" content="$discoveredList">
            <meta name="ajs-keyboardshortcut-hash" content="f372abdc7d1a6481c736efc7686d149c">
            <meta id="team-calendars-has-jira-link" content="true">
            <meta name="ajs-team-calendars-display-time-format" content="displayTimeFormat12">
            <meta id="team-calendars-display-week-number" content="false">
            <meta id="team-calendars-user-timezone" content="Etc/UTC">
            <script type="text/x-template" id="team-calendars-messages" title="team-calendars-messages"><fieldset class="i18n hidden"><input type="hidden" name="calendar3.month.long.july" value="July"><input type="hidden" name="calendar3.day.short.wednesday" value="Wed"><input type="hidden" name="calendar3.day.short.thursday" value="Thu"><input type="hidden" name="calendar3.month.short.march" value="Mar"><input type="hidden" name="calendar3.month.long.april" value="April"><input type="hidden" name="calendar3.month.long.october" value="October"><input type="hidden" name="calendar3.month.long.august" value="August"><input type="hidden" name="calendar3.month.short.july" value="Jul"><input type="hidden" name="calendar3.month.short.may" value="May"><input type="hidden" name="calendar3.month.short.november" value="Nov"><input type="hidden" name="calendar3.day.long.friday" value="Friday"><input type="hidden" name="calendar3.day.long.sunday" value="Sunday"><input type="hidden" name="calendar3.day.long.saturday" value="Saturday"><input type="hidden" name="calendar3.month.short.april" value="Apr"><input type="hidden" name="calendar3.day.long.wednesday" value="Wednesday"><input type="hidden" name="calendar3.month.long.december" value="December"><input type="hidden" name="calendar3.month.short.october" value="Oct"><input type="hidden" name="calendar3.day.long.monday" value="Monday"><input type="hidden" name="calendar3.month.short.june" value="Jun"><input type="hidden" name="calendar3.day.short.monday" value="Mon"><input type="hidden" name="calendar3.day.short.tuesday" value="Tue"><input type="hidden" name="calendar3.day.short.saturday" value="Sat"><input type="hidden" name="calendar3.month.long.march" value="March"><input type="hidden" name="calendar3.month.long.june" value="June"><input type="hidden" name="calendar3.month.short.february" value="Feb"><input type="hidden" name="calendar3.month.short.august" value="Aug"><input type="hidden" name="calendar3.month.short.december" value="Dec"><input type="hidden" name="calendar3.day.short.sunday" value="Sun"><input type="hidden" name="calendar3.month.long.february" value="February"><input type="hidden" name="calendar3.day.long.tuesday" value="Tuesday"><input type="hidden" name="calendar3.month.long.may" value="May"><input type="hidden" name="calendar3.month.long.september" value="September"><input type="hidden" name="calendar3.month.long.november" value="November"><input type="hidden" name="calendar3.month.short.january" value="Jan"><input type="hidden" name="calendar3.month.short.september" value="Sep"><input type="hidden" name="calendar3.day.long.thursday" value="Thursday"><input type="hidden" name="calendar3.month.long.january" value="January"><input type="hidden" name="calendar3.day.short.friday" value="Fri"></fieldset></script>
            
    
    
            <meta name="ajs-page-title" content="Tutorial">
            <meta name="ajs-latest-published-page-title" content="Tutorial">
            <meta name="ajs-space-name" content="Apache Hive">
            <meta name="ajs-page-id" content="27362061">
            <meta name="ajs-latest-page-id" content="27362061">
            <meta name="ajs-content-type" content="page">
            <meta name="ajs-parent-page-id" content="">
            <meta name="ajs-space-key" content="Hive">
            <meta name="ajs-max-number-editors" content="12">
            <meta name="ajs-macro-placeholder-timeout" content="5000">
            <meta name="ajs-jira-metadata-count" content="0">
            <meta name="ajs-from-page-title" content="">
            <meta name="ajs-can-remove-page" content="false">
            <meta name="ajs-can-remove-page-hierarchy" content="false">
            <meta name="ajs-browse-page-tree-mode" content="view">
            <meta name="ajs-shared-drafts" content="true">
            <meta name="ajs-context-path" content="/confluence">
            <meta name="ajs-base-url" content="https://cwiki.apache.org/confluence">
            <meta name="ajs-version-number" content="7.13.2">
            <meta name="ajs-build-number" content="8703">
            <meta name="ajs-remote-user" content="">
            <meta name="ajs-remote-user-key" content="">
            <meta name="ajs-remote-user-has-licensed-access" content="false">
            <meta name="ajs-remote-user-has-browse-users-permission" content="false">
            <meta name="ajs-current-user-fullname" content="">
            <meta name="ajs-current-user-avatar-url" content="">
            <meta name="ajs-current-user-avatar-uri-reference" content="/confluence/images/icons/profilepics/anonymous.svg">
            <meta name="ajs-static-resource-url-prefix" content="/confluence/s/6dvx22/8703/4mhn8a/_">
            <meta name="ajs-global-settings-attachment-max-size" content="20971520">
            <meta name="ajs-global-settings-quick-search-enabled" content="true">
            <meta name="ajs-user-locale" content="en_GB">
            <meta name="ajs-enabled-dark-features" content="site-wide.shared-drafts,site-wide.synchrony,clc.quick.create,confluence.view.edit.transition,cql.search.screen,confluence-inline-comments-resolved,frontend.editor.v4,http.session.registrar,nps.survey.inline.dialog,confluence.efi.onboarding.new.templates,frontend.editor.v4.compatibility,atlassian.cdn.static.assets,pdf-preview,previews.sharing,previews.versions,file-annotations,confluence.efi.onboarding.rich.space.content,collaborative-audit-log,confluence.reindex.improvements,previews.conversion-service,editor.ajax.save,read.only.mode,graphql,previews.trigger-all-file-types,attachment.extracted.text.extractor,lucene.caching.filter,confluence.table.resizable,notification.batch,previews.sharing.pushstate,confluence-inline-comments-rich-editor,tc.tacca.dacca,site-wide.synchrony.opt-in,file-annotations.likes,gatekeeper-ui-v2,v2.content.name.searcher,mobile.supported.version,pulp,confluence-inline-comments,confluence-inline-comments-dangling-comment,quick-reload-inline-comments-flags">
            <meta name="ajs-atl-token" content="d7833c7da397e2f88a76912a1879e0225325829d">
            <meta name="ajs-confluence-flavour" content="VANILLA">
            <meta name="ajs-user-date-pattern" content="dd MMM yyyy">
            <meta name="ajs-access-mode" content="READ_WRITE">
            <meta name="ajs-render-mode" content="READ_WRITE">
            <meta name="ajs-date.format" content="MMM dd, yyyy">
    
    <link rel="shortcut icon" href="https://cwiki.apache.org/confluence/s/6dvx22/8703/4mhn8a/1/_/favicon.ico">
    <link rel="icon" type="image/x-icon" href="https://cwiki.apache.org/confluence/s/6dvx22/8703/4mhn8a/1/_/favicon.ico">

<link rel="search" type="application/opensearchdescription+xml" href="https://cwiki.apache.org/confluence/opensearch/osd.action" title="Apache Software Foundation"/>
    
                    
            <meta name="ajs-create-issue-metadata-show-discovery" content="false">
            

    <script>
window.WRM=window.WRM||{};window.WRM._unparsedData=window.WRM._unparsedData||{};window.WRM._unparsedErrors=window.WRM._unparsedErrors||{};
WRM._unparsedData["com.atlassian.plugins.atlassian-plugins-webresource-plugin:context-path.context-path"]="\u0022\u005C/confluence\u0022";
WRM._unparsedData["com.atlassian.confluence.plugins.confluence-feature-discovery-plugin:confluence-feature-discovery-plugin-resources.test-mode"]="false";
WRM._unparsedData["com.atlassian.confluence.plugins.synchrony-interop:synchrony-status-banner-loader.synchrony-status"]="false";
WRM._unparsedData["com.atlassian.analytics.analytics-client:policy-update-init.policy-update-data-provider"]="false";
WRM._unparsedData["com.atlassian.analytics.analytics-client:programmatic-analytics-init.programmatic-analytics-data-provider"]="false";
WRM._unparsedData["com.atlassian.applinks.applinks-plugin:applinks-common-exported.applinks-help-paths"]="{\u0022entries\u0022:{\u0022applinks.docs.root\u0022:\u0022https://confluence.atlassian.com/display/APPLINKS-072/\u0022,\u0022applinks.docs.diagnostics.troubleshoot.sslunmatched\u0022:\u0022SSL+and+application+link+troubleshooting+guide\u0022,\u0022applinks.docs.diagnostics.troubleshoot.oauthsignatureinvalid\u0022:\u0022OAuth+troubleshooting+guide\u0022,\u0022applinks.docs.diagnostics.troubleshoot.oauthtimestamprefused\u0022:\u0022OAuth+troubleshooting+guide\u0022,\u0022applinks.docs.delete.entity.link\u0022:\u0022Create+links+between+projects\u0022,\u0022applinks.docs.adding.application.link\u0022:\u0022Link+Atlassian+applications+to+work+together\u0022,\u0022applinks.docs.administration.guide\u0022:\u0022Application+Links+Documentation\u0022,\u0022applinks.docs.oauth.security\u0022:\u0022OAuth+security+for+application+links\u0022,\u0022applinks.docs.troubleshoot.application.links\u0022:\u0022Troubleshoot+application+links\u0022,\u0022applinks.docs.diagnostics.troubleshoot.unknownerror\u0022:\u0022Network+and+connectivity+troubleshooting+guide\u0022,\u0022applinks.docs.configuring.auth.trusted.apps\u0022:\u0022Configuring+Trusted+Applications+authentication+for+an+application+link\u0022,\u0022applinks.docs.diagnostics.troubleshoot.authlevelunsupported\u0022:\u0022OAuth+troubleshooting+guide\u0022,\u0022applinks.docs.diagnostics.troubleshoot.ssluntrusted\u0022:\u0022SSL+and+application+link+troubleshooting+guide\u0022,\u0022applinks.docs.diagnostics.troubleshoot.unknownhost\u0022:\u0022Network+and+connectivity+troubleshooting+guide\u0022,\u0022applinks.docs.delete.application.link\u0022:\u0022Link+Atlassian+applications+to+work+together\u0022,\u0022applinks.docs.adding.project.link\u0022:\u0022Configuring+Project+links+across+Applications\u0022,\u0022applinks.docs.link.applications\u0022:\u0022Link+Atlassian+applications+to+work+together\u0022,\u0022applinks.docs.diagnostics.troubleshoot.oauthproblem\u0022:\u0022OAuth+troubleshooting+guide\u0022,\u0022applinks.docs.diagnostics.troubleshoot.migration\u0022:\u0022Update+application+links+to+use+OAuth\u0022,\u0022applinks.docs.relocate.application.link\u0022:\u0022Link+Atlassian+applications+to+work+together\u0022,\u0022applinks.docs.administering.entity.links\u0022:\u0022Create+links+between+projects\u0022,\u0022applinks.docs.upgrade.application.link\u0022:\u0022OAuth+security+for+application+links\u0022,\u0022applinks.docs.diagnostics.troubleshoot.connectionrefused\u0022:\u0022Network+and+connectivity+troubleshooting+guide\u0022,\u0022applinks.docs.configuring.auth.oauth\u0022:\u0022OAuth+security+for+application+links\u0022,\u0022applinks.docs.insufficient.remote.permission\u0022:\u0022OAuth+security+for+application+links\u0022,\u0022applinks.docs.configuring.application.link.auth\u0022:\u0022OAuth+security+for+application+links\u0022,\u0022applinks.docs.diagnostics\u0022:\u0022Application+links+diagnostics\u0022,\u0022applinks.docs.configured.authentication.types\u0022:\u0022OAuth+security+for+application+links\u0022,\u0022applinks.docs.adding.entity.link\u0022:\u0022Create+links+between+projects\u0022,\u0022applinks.docs.diagnostics.troubleshoot.unexpectedresponse\u0022:\u0022Network+and+connectivity+troubleshooting+guide\u0022,\u0022applinks.docs.configuring.auth.basic\u0022:\u0022Configuring+Basic+HTTP+Authentication+for+an+Application+Link\u0022,\u0022applinks.docs.diagnostics.troubleshoot.authlevelmismatch\u0022:\u0022OAuth+troubleshooting+guide\u0022}}";
WRM._unparsedData["com.atlassian.applinks.applinks-plugin:applinks-common-exported.applinks-types"]="{\u0022crowd\u0022:\u0022Crowd\u0022,\u0022confluence\u0022:\u0022Confluence\u0022,\u0022fecru\u0022:\u0022FishEye / Crucible\u0022,\u0022stash\u0022:\u0022Stash\u0022,\u0022jira\u0022:\u0022Jira\u0022,\u0022refapp\u0022:\u0022Reference Application\u0022,\u0022bamboo\u0022:\u0022Bamboo\u0022,\u0022generic\u0022:\u0022Generic Application\u0022}";
WRM._unparsedData["com.atlassian.applinks.applinks-plugin:applinks-common-exported.entity-types"]="{\u0022singular\u0022:{\u0022refapp.charlie\u0022:\u0022Charlie\u0022,\u0022fecru.project\u0022:\u0022Crucible Project\u0022,\u0022fecru.repository\u0022:\u0022FishEye Repository\u0022,\u0022stash.project\u0022:\u0022Stash Project\u0022,\u0022generic.entity\u0022:\u0022Generic Project\u0022,\u0022confluence.space\u0022:\u0022Confluence Space\u0022,\u0022bamboo.project\u0022:\u0022Bamboo Project\u0022,\u0022jira.project\u0022:\u0022Jira Project\u0022},\u0022plural\u0022:{\u0022refapp.charlie\u0022:\u0022Charlies\u0022,\u0022fecru.project\u0022:\u0022Crucible Projects\u0022,\u0022fecru.repository\u0022:\u0022FishEye Repositories\u0022,\u0022stash.project\u0022:\u0022Stash Projects\u0022,\u0022generic.entity\u0022:\u0022Generic Projects\u0022,\u0022confluence.space\u0022:\u0022Confluence Spaces\u0022,\u0022bamboo.project\u0022:\u0022Bamboo Projects\u0022,\u0022jira.project\u0022:\u0022Jira Projects\u0022}}";
WRM._unparsedData["com.atlassian.applinks.applinks-plugin:applinks-common-exported.authentication-types"]="{\u0022com.atlassian.applinks.api.auth.types.BasicAuthenticationProvider\u0022:\u0022Basic Access\u0022,\u0022com.atlassian.applinks.api.auth.types.TrustedAppsAuthenticationProvider\u0022:\u0022Trusted Applications\u0022,\u0022com.atlassian.applinks.api.auth.types.CorsAuthenticationProvider\u0022:\u0022CORS\u0022,\u0022com.atlassian.applinks.api.auth.types.OAuthAuthenticationProvider\u0022:\u0022OAuth\u0022,\u0022com.atlassian.applinks.api.auth.types.TwoLeggedOAuthAuthenticationProvider\u0022:\u0022OAuth\u0022,\u0022com.atlassian.applinks.api.auth.types.TwoLeggedOAuthWithImpersonationAuthenticationProvider\u0022:\u0022OAuth\u0022}";
WRM._unparsedData["com.atlassian.confluence.plugins.confluence-license-banner:confluence-license-banner-resources.license-details"]="{\u0022daysBeforeLicenseExpiry\u0022:0,\u0022daysBeforeMaintenanceExpiry\u0022:0,\u0022showLicenseExpiryBanner\u0022:false,\u0022showMaintenanceExpiryBanner\u0022:false,\u0022renewUrl\u0022:null,\u0022salesUrl\u0022:null}";
WRM._unparsedData["com.atlassian.confluence.plugins.confluence-search-ui-plugin:confluence-search-ui-plugin-resources.i18n-data"]="{\u0022search.ui.recent.link.text\u0022:\u0022View more recently visited\u0022,\u0022search.ui.filter.space.category.input.label\u0022:\u0022Find space categories...\u0022,\u0022search.ui.search.results.empty\u0022:\u0022We couldn\u005Cu0027\u005Cu0027t find anything matching \u005C\u0022{0}\u005C\u0022.\u0022,\u0022search.ui.filter.clear.selected\u0022:\u0022Clear selected items\u0022,\u0022search.ui.content.name.search.items.panel.load.all.top.items.button.text\u0022:\u0022Show more app results...\u0022,\u0022search.ui.filter.space.archive.label\u0022:\u0022Search archived spaces\u0022,\u0022search.ui.filter.label\u0022:\u0022filter\u0022,\u0022search.ui.filter.contributor.button.text\u0022:\u0022Contributor\u0022,\u0022search.ui.filter.date.all.text\u0022:\u0022Any time\u0022,\u0022search.ui.filter.space.current.label\u0022:\u0022CURRENT\u0022,\u0022search.ui.clear.input.button.text\u0022:\u0022Clear text\u0022,\u0022search.ui.search.results.clear.button\u0022:\u0022clear your filters.\u0022,\u0022search.ui.filter.date.hour.text\u0022:\u0022The past day\u0022,\u0022help.search.ui.link.title\u0022:\u0022Search tips\u0022,\u0022search.ui.filters.heading\u0022:\u0022Filter by\u0022,\u0022search.ui.filter.label.input.label\u0022:\u0022Find labels...\u0022,\u0022search.ui.recent.items.anonymous\u0022:\u0022Start exploring. Your search results will appear here.\u0022,\u0022search.ui.filter.date.month.text\u0022:\u0022The past month\u0022,\u0022search.ui.input.label\u0022:\u0022Search\u0022,\u0022search.ui.search.result\u0022:\u0022{0,choice,1#{0} search result|1\u005Cu003c{0} search results}\u0022,\u0022search.ui.infinite.scroll.button.text\u0022:\u0022More results\u0022,\u0022search.ui.filter.date.button.text\u0022:\u0022Date\u0022,\u0022search.ui.filter.date.week.text\u0022:\u0022The past week\u0022,\u0022search.ui.filter.label.button.text\u0022:\u0022Label\u0022,\u0022search.ui.input.alert\u0022:\u0022Hit enter to search\u0022,\u0022search.ui.result.subtitle.calendar\u0022:\u0022Team calendar\u0022,\u0022search.ui.filter.no.result.text\u0022:\u0022We can\u005Cu0027\u005Cu0027t find anything matching your search\u0022,\u0022search.ui.filter.date.heading\u0022:\u0022Last modified within\u0022,\u0022search.ui.result.subtitle.user\u0022:\u0022User profile\u0022,\u0022search.ui.filter.contributor.input.label\u0022:\u0022Find people...\u0022,\u0022search.ui.filter.content.type.button.text\u0022:\u0022Type\u0022,\u0022search.ui.filter.space.input.label\u0022:\u0022Find spaces...\u0022,\u0022search.ui.filter.date.year.text\u0022:\u0022The past year\u0022,\u0022search.ui.advanced.search.link.text\u0022:\u0022Advanced search\u0022,\u0022search.ui.filter.space.button.text\u0022:\u0022Space\u0022,\u0022search.ui.generic.error\u0022:\u0022Something went wrong. Refresh the page, or contact your admin if this keeps happening.\u0022,\u0022search.ui.recent.spaces\u0022:\u0022Recent Spaces\u0022,\u0022search.ui.search.results.clear.line2\u0022:\u0022Try a different search term or\u0022,\u0022search.ui.filter.space.category.button.text\u0022:\u0022Space category\u0022,\u0022search.ui.search.results.clear.line1\u0022:\u0022We couldn\u005Cu0027\u005Cu0027t find anything matching your search.\u0022,\u0022search.ui.content.name.search.items.panel.load.all.top.items.admin.button.text\u0022:\u0022Show more settings and app results...\u0022,\u0022search.ui.recent.pages\u0022:\u0022Recently visited\u0022,\u0022search.ui.search.result.anonymous\u0022:\u0022{0,choice,1#{0} search result|1\u005Cu003c{0} search results}. Have an account? {1}Log in{2} to expand your search.\u0022,\u0022search.ui.recent.items.empty\u0022:\u0022Start exploring. Pages and spaces you\u005Cu0027\u005Cu0027ve visited recently will appear here.\u0022,\u0022search.ui.result.subtitle.space\u0022:\u0022Space\u0022,\u0022search.ui.filter.space.init.heading\u0022:\u0022recent spaces\u0022}";
if(window.WRM._dataArrived)window.WRM._dataArrived();</script>
<link type="text/css" rel="stylesheet" href="../../s/ad0cdaf669e3a7800fb6fa6452e260e4-CDN/6dvx22/8703/4mhn8a/6b1577085985a611eea3c1e80e0e7e93/_/download/contextbatch/css/_super/batch.css" data-wrm-key="_super" data-wrm-batch-type="context" media="all">
<link type="text/css" rel="stylesheet" href="../../s/585884a9f3984b0aaecef0baf40c1e6e-CDN/6dvx22/8703/4mhn8a/e6aaebbd7baa9a045ec96374ae08d3b2/_/download/contextbatch/css/atl.confluence.plugins.pagetree-desktop%2cmain%2cvi/batch1203.css?gatekeeper-ui-v2=true&amp;highlightactions=true&amp;hostenabled=true" data-wrm-key="atl.confluence.plugins.pagetree-desktop,main,viewcontent,atl.general,page,atl.comments,-_super" data-wrm-batch-type="context" media="all">
<script type="text/javascript" src="../../s/58e418cc99c782d6bf891d0ee81d3e82-CDN/6dvx22/8703/4mhn8a/6b1577085985a611eea3c1e80e0e7e93/_/download/contextbatch/js/_super/batch6116.js?locale=en-GB" data-wrm-key="_super" data-wrm-batch-type="context" data-initially-rendered></script>
<script type="text/javascript" src="../../s/d8f9091841663d4e3446e48379e476f1-CDN/6dvx22/8703/4mhn8a/e6aaebbd7baa9a045ec96374ae08d3b2/_/download/contextbatch/js/atl.confluence.plugins.pagetree-desktop%2cmain%2cvi/batch3a32.js?gatekeeper-ui-v2=true&amp;highlightactions=true&amp;hostenabled=true&amp;locale=en-GB" data-wrm-key="atl.confluence.plugins.pagetree-desktop,main,viewcontent,atl.general,page,atl.comments,-_super" data-wrm-batch-type="context" data-initially-rendered></script>

    

        
    

        
        <meta name="ajs-site-title" content="Apache Software Foundation" />
            
    

    
                <link rel="canonical" href="Tutorial.html">
        <link rel="shortlink" href="https://cwiki.apache.org/confluence/x/DYOhAQ">
    <meta name="wikilink" content="[Hive:Tutorial]">
    <meta name="page-version" content="56">
    <meta name="ajs-page-version" content="56">

</head>

    
<body      id="com-atlassian-confluence" class="theme-default  aui-layout aui-theme-default">

        
            

<fieldset class="parameters hidden" style="display: none;">
            <input type="hidden" id="listAnalyticsKey" value="19"/>
        <input type="hidden" id="listAnalyticsDomain" value="comalatech.matomo.cloud"/>
    </fieldset>
            <div id='stp-licenseStatus-banner'></div>
    <ul id="assistive-skip-links" class="assistive">
    <li><a href="#title-heading">Skip to content</a></li>
    <li><a href="#breadcrumbs">Skip to breadcrumbs</a></li>
    <li><a href="#header-menu-bar">Skip to header menu</a></li>
    <li><a href="#navigation">Skip to action menu</a></li>
    <li><a href="#quick-search-query">Skip to quick search</a></li>
</ul>
<div id="page">
<div id="full-height-container">
    <div id="header-precursor">
        <div class="cell">
            
                            </div>
    </div>
        





<header id="header" role="banner">
    <nav class="aui-header aui-dropdown2-trigger-group" aria-label="Site"><div class="aui-header-inner"><div class="aui-header-before"><button class=" aui-dropdown2-trigger app-switcher-trigger aui-dropdown2-trigger-arrowless" aria-controls="app-switcher" aria-haspopup="true" role="button" data-aui-trigger href="#app-switcher"><span class="aui-icon aui-icon-small aui-iconfont-appswitcher">Linked Applications</span></button><div id="app-switcher" class="aui-dropdown2 aui-style-default" role="menu" hidden data-is-switcher="true" data-environment="{&quot;isUserAdmin&quot;:false,&quot;isAppSuggestionAvailable&quot;:false,&quot;isSiteAdminUser&quot;:false}"><div class="app-switcher-loading">Loading&hellip;</div></div></div><div class="aui-header-primary"><span id="logo" class="aui-header-logo aui-header-logo-confluence"><a href="https://cwiki.apache.org/confluence/" aria-label="Go to home page"><span class="aui-header-logo-device">Apache Software Foundation</span></a></span><ul class="aui-nav">
                            <li>
            
        
        
<a  id="space-directory-link" href="https://cwiki.apache.org/confluence/spacedirectory/view.action"  class=" aui-nav-imagelink"   title="Spaces">
            <span>Spaces</span>
    </a>
        </li>
                                <li class="aui-buttons">
            </li>
</ul>
</div><div class="aui-header-secondary"><ul class="aui-nav">
                        <li>
        <div id="search-ui" class="aui-quicksearch dont-default-focus header-quicksearch"><input id="quick-search-query" aria-label="Search" placeholder="Search" type="text" /><div id="quick-search-alert" role="alert">Hit enter to search</div><aui-spinner size="small"></aui-spinner></div>
    </li>
        <li>
            
        <a id="help-menu-link" class="aui-nav-link aui-dropdown2-trigger aui-dropdown2-trigger-arrowless" href="#" aria-haspopup="true" aria-owns="help-menu-link-content" title="Help">
        <span class="aui-icon aui-icon-small aui-iconfont-question-filled">Help</span>
    </a>
    <nav id="help-menu-link-content" class="aui-dropdown2 aui-style-default" aria-hidden="true">
                    <div class="aui-dropdown2-section">
                                <ul  id="help-menu-link-leading" class="aui-list-truncate section-leading first">
                                            <li>
        
            
<a  id="confluence-help-link" href="https://docs.atlassian.com/confluence/docs-713/" class="    "      title="Visit the Confluence documentation home"  target="_blank"
>
        Online Help
</a>
</li>
                                            <li>
    
            
<a  id="keyboard-shortcuts-link" href="https://cwiki.apache.org/confluence" class="    "      title="View available keyboard shortcuts" >
        Keyboard Shortcuts
</a>
</li>
                                            <li>
    
            
<a  id="feed-builder-link" href="https://cwiki.apache.org/confluence/dashboard/configurerssfeed.action" class="    "      title="Create your custom RSS feed." >
        Feed Builder
</a>
</li>
                                            <li>
    
            
<a  id="whats-new-menu-link" href="https://docs.atlassian.com/confluence/docs-713/help.whats.new.iframe.link" class="    "      title="" >
        What’s new
</a>
</li>
                                            <li>
    
            
<a  id="whats-new-menu-link" href="https://confluence.atlassian.com/display/DOC/Confluence+7.13+Release+Notes" class="    "      title="" >
        What’s new
</a>
</li>
                                            <li>
    
            
<a  id="gadget-directory-link" href="https://cwiki.apache.org/confluence" class="   user-item administration-link "      title="Browse gadgets provided by Confluence" >
        Available Gadgets
</a>
</li>
                                            <li>
    
            
<a  id="confluence-about-link" href="https://cwiki.apache.org/confluence/aboutconfluencepage.action" class="    "      title="Get more information about Confluence" >
        About Confluence
</a>
</li>
                                    </ul>
            </div>
            </nav>
    
    </li>
        <li>
                
    
    </li>
        <li>
            
    </li>
        <li>
                                            <li>
        
            
<a  id="login-link" href="https://cwiki.apache.org/confluence/login.action?os_destination=%2Fdisplay%2FHive%2FTutorial" class="   user-item login-link "      title="" >
        Log in
</a>
</li>
                        <li>
    
            
<a  id="signup-link" href="https://cwiki.apache.org/confluence/signup.action" class="   user-item signup-link "      title="" >
        Sign up
</a>
</li>
                        
    </li>
    </ul>
</div></div><!-- .aui-header-inner--></nav><!-- .aui-header -->
    <br class="clear">
</header>
    

    
    	<div class="ia-splitter">
    		<div class="ia-splitter-left">
    			<div class="ia-fixed-sidebar">
                                            
                            <div class="acs-side-bar ia-scrollable-section"><div class="acs-side-bar-space-info tipsy-enabled" data-configure-tooltip="Edit space details"><div class="avatar"><div class="space-logo" data-key="Hive" data-name="Apache Hive" data-entity-type="confluence.space"><div class="avatar-img-container"><div class="avatar-img-wrapper"><a href="Home.html" title="Apache Hive"><img class="avatar-img" src="https://cwiki.apache.org/confluence/download/attachments/27362113/Hive?version=2&amp;modificationDate=1317659390000&amp;api=v2" alt="Apache Hive"></a></div></div></div></div><div class="space-information-container"><div class="name"><a href="Home.html" title="Apache Hive">Apache Hive</a></div><div class="flyout-handle icon aui-icon aui-icon-small aui-iconfont-edit"></div></div></div><div class="acs-side-bar-content"><div class="acs-nav-wrapper"><div class="acs-nav" data-has-create-permission="false" data-quick-links-state="null" data-page-tree-state="null" data-nav-type="pages"><div class="acs-nav-sections"><div class="main-links-section "><ul class="acs-nav-list"><li class="acs-nav-item wiki current-item" aria-current="true" data-collector-key="spacebar-pages"><a class="acs-nav-item-link tipsy-enabled" href="https://cwiki.apache.org/confluence/collector/pages.action?key=Hive" data-collapsed-tooltip="Pages"><span class="icon"></span><span class="acs-nav-item-label">Pages</span></a></li><li class="acs-nav-item blog" data-collector-key="spacebar-blogs"><a class="acs-nav-item-link tipsy-enabled" href="https://cwiki.apache.org/confluence/pages/viewrecentblogposts.action?key=Hive" data-collapsed-tooltip="Blog"><span class="icon"></span><span class="acs-nav-item-label">Blog</span></a></li></ul></div><div class="quick-links-wrapper"><h5 class="ia-quick-links-header-title">Space shortcuts</h5><div class="quick-links-section tipsy-enabled "><ul class="acs-nav-list"><li class="acs-nav-item pinned_page blueprint kb-how-to-article"><a class="acs-nav-item-link tipsy-enabled" href="How-to%2barticles.html" data-collapsed-tooltip="null"><span class="icon"></span><span class="acs-nav-item-label">How-to articles</span></a></li></ul></div></div></div></div></div><div class="ia-secondary-container tipsy-enabled" data-tree-type="pages"><div class="ia-secondary-header"><h5 class="ia-secondary-header-title pages"><span class="label">Child pages</span></h5></div><div class="ia-secondary-parent-content"><ul class="parent ia-secondary-header-title wiki"><li class="parent-item"><a class="parent-item-link" href="https://cwiki.apache.org/confluence/collector/pages.action?key=Hive" title="Pages"><span class="icon"></span><span class="label">Pages</span></a></li></ul></div><div class="ia-secondary-current-content"><ul class="ia-secondary-currentPage-title wiki current-item"><li><span class="icon"></span><span class="label">Tutorial</span></li></ul></div><div class="ia-secondary-content"><div class="contextual-nav-child-pages"></div></div></div></div><div class="hidden"><a href="https://cwiki.apache.org/confluence/collector/pages.action?key=Hive" id="space-pages-link"></a><script type="text/x-template" title="logo-config-content"><h2>Space Details</h2><div class="personal-space-logo-hint">Your profile picture is used as the logo for your personal space. <a href="/confluence/users/profile/editmyprofilepicture.action" target="_blank">Change your profile picture</a>.</div></script></div></div><div class="space-tools-section"><div id="space-tools-menu-additional-items" class="hidden"><div data-label="Browse pages" data-class="" data-href="/confluence/pages/reorderpages.action?key=Hive">Browse pages</div></div><button id="space-tools-menu-trigger"  class=" aui-dropdown2-trigger aui-button aui-button-subtle tipsy-enabled aui-dropdown2-trigger-arrowless " aria-controls="space-tools-menu" aria-haspopup="true" role="button" data-aui-trigger><span class="aui-icon aui-icon-small aui-iconfont-configure">Configure</span><span class="aui-button-label">Space tools</span><span class="aui-icon "></span></button><div id="space-tools-menu" class="aui-dropdown2 aui-style-default space-tools-dropdown" role="menu" hidden data-aui-alignment="top left"></div><a href="#" role="button" class="expand-collapse-trigger aui-icon aui-icon-small aui-iconfont-chevron-double-left" aria-expanded="true"></a></div>
                    
                        			</div>
    		</div>
        <!-- \#header -->

            
    
        <div id="main" class=" aui-page-panel">
                        <div id="main-header">
                        
    <div id="navigation" class="content-navigation view">
                    <ul class="ajs-menu-bar">
                                            
        <li class="normal ajs-menu-item">
        <a id="action-menu-link" class="action aui-dropdown2-trigger-arrowless aui-button aui-button-subtle ajs-menu-title aui-dropdown2-trigger" href="#" aria-haspopup="true" aria-label="More options" aria-owns="action-menu" data-container="#navigation">
            <span>
                                    <span class="aui-icon aui-icon-small aui-iconfont-more" aria-label="More options"></span>
                                
            </span>
        </a>         <div id="action-menu" class="aui-dropdown2 aui-style-default" aria-hidden="true">
                            <div class="aui-dropdown2-section">
                    <ul  id="action-menu-primary"                         class="section-primary first">
                                                    <li>

    
        
    
                                                        
    
    
            <a  id="view-attachments-link" href="https://cwiki.apache.org/confluence/pages/viewpageattachments.action?pageId=27362061" rel="nofollow" class="action-view-attachments"  accessKey="t"  title="View Attachments" >
                        <span>
                                A<u>t</u>tachments (0)
            </span>        </a>
    </li>
                                                <li>

    
        
    
                                                        
    
    
            <a  id="action-view-history-link" href="https://cwiki.apache.org/confluence/pages/viewpreviousversions.action?pageId=27362061" rel="nofollow" class="action-view-history"   title="" >
                        <span>
                                Page History
            </span>        </a>
    </li>
                                                <li>

    
        
    
                                                        
    
    
            <a  id="who-can-view-button-ak-button" href="https://cwiki.apache.org/confluence" rel="nofollow" class="who-can-view-link"   title="" >
                        <span>
                                People who can view
            </span>        </a>
    </li>
                                        </ul>
                </div>
                            <div class="aui-dropdown2-section">
                    <ul  id="action-menu-secondary"                         class="section-secondary">
                                                    <li>

    
        
    
                                                        
    
    
            <a  id="view-resolved-comments" href="https://cwiki.apache.org/confluence" rel="nofollow" class=""   title="" >
                        <span>
                                Resolved comments
            </span>        </a>
    </li>
                                                <li>

    
        
    
                                                        
    
    
            <a  id="view-page-info-link" href="https://cwiki.apache.org/confluence/pages/viewinfo.action?pageId=27362061" rel="nofollow" class="action-view-info"   title="" >
                        <span>
                                Page Information
            </span>        </a>
    </li>
                                                <li>

    
        
    
                                                        
    
    
            <a  id="view-in-hierarchy-link" href="https://cwiki.apache.org/confluence/pages/reorderpages.action?key=Hive&amp;openId=27362061#selectedPageInHierarchy" rel="nofollow" class=""   title="" >
                        <span>
                                View in Hierarchy
            </span>        </a>
    </li>
                                                <li>

    
        
    
                                                        
    
    
            <a  id="action-view-source-link" href="https://cwiki.apache.org/confluence/plugins/viewsource/viewpagesrc.action?pageId=27362061" rel="nofollow" class="action-view-source popup-link"   title="" >
                        <span>
                                View Source
            </span>        </a>
    </li>
                                                <li>

    
        
    
                                                        
    
    
            <a  id="delete-all-comments-link-link" href="https://cwiki.apache.org/confluence/plugins/aptis/deleteAllComments/ask-user.action?pageId=27362061" rel="nofollow" class=""   title="" >
                        <span>
                                Delete comments
            </span>        </a>
    </li>
                                                <li>

    
        
    
                                                        
    
    
            <a  id="action-export-pdf-link" href="https://cwiki.apache.org/confluence/spaces/flyingpdf/pdfpageexport.action?pageId=27362061" rel="nofollow" class=""   title="" >
                        <span>
                                Export to PDF
            </span>        </a>
    </li>
                                                <li>

    
        
    
                                                        
    
    
            <a  id="com-k15t-confluence-scroll-epub-launcher" href="https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=27362061" rel="nofollow" class=""   title="" >
                        <span>
                                Export to EPUB
            </span>        </a>
    </li>
                                                <li>

    
        
    
                                                        
    
    
            <a  id="action-export-word-link" href="https://cwiki.apache.org/confluence/exportword?pageId=27362061" rel="nofollow" class="action-export-word"   title="" >
                        <span>
                                Export to Word
            </span>        </a>
    </li>
                                        </ul>
                </div>
                            <div class="aui-dropdown2-section">
                    <ul  id="action-menu-modify"                         class="section-modify">
                                                    <li>

    
        
    
                                                        
    
    
            <a  id="treecopy-action" href="https://cwiki.apache.org/confluence/plugins/tree-copy/preparing-copying.action?pageId=27362061" rel="nofollow" class=""   title="" >
                        <span>
                                Copy Page Tree
            </span>        </a>
    </li>
                                        </ul>
                </div>
                    </div>
    </li>
            </ul>
    </div>

            
            <div id="title-heading" class="pagetitle with-breadcrumbs">
                
                                    <div id="breadcrumb-section">
                        
    
    
    <ol id="breadcrumbs">
                                        
                        
        <li class="first" >
                        
                            <span class=""><a href="https://cwiki.apache.org/confluence/collector/pages.action?key=Hive">Pages</a></span>
                                                                    </ol>


                    </div>
                
                
        <a href="#page-banner-end" class="assistive">Skip to end of banner</a>
<div id="page-banner-start" class="assistive"></div>

                    
            <div id="page-metadata-banner"><ul class="banner"><li id="system-content-items" class="noprint"><a href="#" title="Unrestricted" id="content-metadata-page-restrictions-hidden" class="hidden"></a></li><li class="page-metadata-item noprinthas-button"  id="content-metadata-jira-wrapper"><a href="#" title="" id="content-metadata-jira" class="aui-button aui-button-subtle content-metadata-jira tipsy-disabled hidden"><span>Jira links</span></a></li></ul></div>
            

<a href="#page-banner-start" class="assistive">Go to start of banner</a>
<div id="page-banner-end" class="assistive"></div>
    

                <h1 id="title-text" class="with-breadcrumbs">
                                                <a href="Tutorial.html">Tutorial</a>
                                    </h1>
            </div>
        </div><!-- \#main-header -->
        
        

        <div id="sidebar-container">
                                                </div><!-- \#sidebar-container -->

        
    

        




            
    

                                
    

    
    
        
    
    
                    
    

    

    
            
        

    
    

    
            
        



    
<div id="content" class="page view">
    


<div id="action-messages">
                        </div>



            <script type="text/x-template" title="searchResultsGrid">
    <table class="aui">
        <thead>
            <tr class="header">
                <th class="search-result-title">Page Title</th>
                <th class="search-result-space">Space</th>
                <th class="search-result-date">Updated</th>
            </tr>
        </thead>
    </table>
</script>
<script type="text/x-template" title="searchResultsGridCount">
    <p class="search-result-count">{0}</p>
</script>
<script type="text/x-template" title="searchResultsGridRow">
    <tr class="search-result">
        <td class="search-result-title"><a href="{1}" class="content-type-{2}"><span>{0}</span></a></td>
        <td class="search-result-space"><a class="space" href="/confluence/display/{4}/" title="{3}">{3}</a></td>
        <td class="search-result-date"><span class="date" title="{6}">{5}</span></td>
    </tr>
</script>
        
    
            

        
                            
    

                    

        
        <a href="#page-metadata-end" class="assistive">Skip to end of metadata</a>
<div id="page-metadata-start" class="assistive"></div>

    <div class="page-metadata">
        <ul>
            <li class="page-metadata-modification-info">
                
        
    
        
    
        
            
            Created by <span class='author'>     <a href="https://cwiki.apache.org/confluence/login.action?os_destination=%2Fusers%2Fviewuserprofile.action%3Fusername%3Dadmin&amp;permissionViolation=true"
                       class="url fn"
                            >Confluence Administrator</a></span>, last modified by <span class='editor'>     <a href="https://cwiki.apache.org/confluence/login.action?os_destination=%2Fusers%2Fviewuserprofile.action%3Fusername%3Djcamachorodriguez&amp;permissionViolation=true"
                       class="url fn"
                            >Jesús Camacho Rodríguez</a></span> on <a class='last-modified' title='Show changes' href='https://cwiki.apache.org/confluence/pages/diffpagesbyversion.action?pageId=27362061&amp;selectedPageVersions=55&amp;selectedPageVersions=56'>Feb 23, 2021</a>
                </li>
        </ul>
    </div>


<a href="#page-metadata-start" class="assistive">Go to start of metadata</a>
<div id="page-metadata-end" class="assistive"></div>

        
                                            
        <div id="main-content" class="wiki-content">
                           
        <h1 id="Tutorial-HiveTutorial"><strong>Hive Tutorial</strong></h1><hr/><p><div class="toc-macro client-side-toc-macro  conf-macro output-block" data-structure="list" data-headerelements="H1,H2" data-hasbody="false" data-macro-name="toc"> </div></p><h1 id="Tutorial-Concepts">Concepts</h1><h2 id="Tutorial-WhatIsHive">What Is Hive</h2><p>Hive is a data warehousing infrastructure based on <a href="http://hadoop.apache.org/" class="external-link" rel="nofollow">Apache Hadoop</a>. Hadoop provides massive scale out and fault tolerance capabilities for data storage and processing on commodity hardware.</p><p>Hive is designed to enable easy data summarization, ad-hoc querying and analysis of large volumes of data. It provides SQL which enables users to do ad-hoc querying, summarization and data analysis easily. At the same time, Hive's SQL gives users multiple places to integrate their own functionality to do custom analysis, such as User Defined Functions (UDFs).  </p><h2 id="Tutorial-WhatHiveIsNOT">What Hive Is NOT</h2><p>Hive is not designed for online transaction processing.  <span>It is best used for traditional data warehousing tasks.</span></p><h2 id="Tutorial-GettingStarted">Getting Started</h2><p>For details on setting up Hive, HiveServer2, and Beeline, please refer to the <a href="GettingStarted.html">GettingStarted</a> guide.</p><p><a href="Books%2babout%2bHive.html">Books about Hive</a> lists some books that may also be helpful for getting started with Hive.</p><p>In the following sections we provide a tutorial on the capabilities of the system. We start by describing the concepts of data types, tables, and partitions (which are very similar to what you would find in a traditional relational DBMS) and then illustrate the capabilities of Hive with the help of some examples.</p><h2 id="Tutorial-DataUnits">Data Units</h2><p>In the order of granularity - Hive data is organized into:</p><ul><li><strong>Databases</strong>: Namespaces function to avoid naming conflicts for tables, views, partitions, columns, and so on.  Databases can also be used to enforce security for a user or group of users.</li><li><strong>Tables</strong>: Homogeneous units of data which have the same schema. An example of a table could be page_views table, where each row could comprise of the following columns (schema):<ul><li><code>timestamp</code><span style="color: rgb(34,34,34);">—</span>which is of INT type that corresponds to a UNIX timestamp of when the page was viewed.</li><li><code>userid</code> <span style="color: rgb(34,34,34);">—</span>which is of BIGINT type that identifies the user who viewed the page.</li><li><code>page_url<span style="color: rgb(34,34,34);">—</span></code>which is of STRING type that captures the location of the page.</li><li><code>referer_url<span style="color: rgb(34,34,34);">—</span></code>which is of STRING that captures the location of the page from where the user arrived at the current page.</li><li><code>IP<span style="color: rgb(34,34,34);">—</span></code>which is of STRING type that captures the IP address from where the page request was made.</li></ul></li><li><strong>Partitions</strong>: Each Table can have one or more partition Keys which determines how the data is stored. Partitions<span style="color: rgb(34,34,34);">—</span>apart from being storage units<span style="color: rgb(34,34,34);">—</span>also allow the user to efficiently identify the rows that satisfy a specified criteria; for example, a date_partition of type STRING and country_partition of type STRING. Each unique value of the partition keys defines a partition of the Table. For example, all &quot;US&quot; data from &quot;2009-12-23&quot; is a partition of the page_views table. Therefore, if you run analysis on only the &quot;US&quot; data for 2009-12-23, you can run that query only on the relevant partition of the table, thereby speeding up the analysis significantly. Note however, that just because a partition is named 2009-12-23 does not mean that it contains all or only data from that date; partitions are named after dates for convenience; it is the user's job to guarantee the relationship between partition name and data content! Partition columns are virtual columns, they are not part of the data itself but are derived on load.</li><li><strong>Buckets</strong> (or <strong>Clusters</strong>): Data in each partition may in turn be divided into Buckets based on the value of a hash function of some column of the Table. For example the page_views table may be bucketed by userid, which is one of the columns, other than the partitions columns, of the page_view table. These can be used to efficiently sample the data.</li></ul><p>Note that it is not necessary for tables to be partitioned or bucketed, but these abstractions allow the system to prune large quantities of data during query processing, resulting in faster query execution.</p><h2 id="Tutorial-TypeSystem">Type System</h2><p>Hive supports primitive and complex data types, as described below. See <a href="LanguageManual%2bTypes.html">Hive Data Types</a> for additional information.</p><h3 id="Tutorial-PrimitiveTypes">Primitive Types</h3><ul><li>Types are associated with the columns in the tables. The following Primitive types are supported:</li><li>Integers<ul><li>TINYINT<span style="color: rgb(34,34,34);">—</span>1 byte integer</li><li>SMALLINT<span style="color: rgb(34,34,34);">—</span>2 byte integer</li><li>INT<span style="color: rgb(34,34,34);">—</span>4 byte integer</li><li>BIGINT<span style="color: rgb(34,34,34);">—</span>8 byte integer</li></ul></li><li>Boolean type<ul><li>BOOLEAN<span style="color: rgb(34,34,34);">—</span>TRUE/FALSE</li></ul></li><li>Floating point numbers<ul><li>FLOAT<span style="color: rgb(34,34,34);">—</span>single precision</li><li>DOUBLE<span style="color: rgb(34,34,34);">—</span>Double precision</li></ul></li><li>Fixed point numbers<ul><li>DECIMAL<span style="color: rgb(34,34,34);">—</span>a fixed point value of user defined scale and precision</li></ul></li><li>String types<ul><li>STRING<span style="color: rgb(34,34,34);">—</span>sequence of characters in a specified character set</li><li>VARCHAR<span style="color: rgb(34,34,34);">—</span>sequence of characters in a specified character set with a maximum length</li><li>CHAR<span style="color: rgb(34,34,34);">—</span>sequence of characters in a specified character set with a defined length</li></ul></li><li>Date and time types<ul><li>TIMESTAMP <span style="color: rgb(34,34,34);">— A date and time without a timezone (&quot;LocalDateTime&quot; semantics)</span></li><li>TIMESTAMP WITH LOCAL TIME ZONE <span style="color: rgb(34,34,34);">—</span> A point in time measured down to nanoseconds (&quot;Instant&quot; semantics)</li><li>DATE<span style="color: rgb(34,34,34);">—</span>a date</li></ul></li><li>Binary types<ul><li>BINARY<span style="color: rgb(34,34,34);">—</span>a sequence of bytes</li></ul></li></ul><p>The Types are organized in the following hierarchy (where the parent is a super type of all the children instances):</p><ul><li>Type<ul><li><div class="table-wrap"><table class="wrapped confluenceTable"><tbody><tr><td class="confluenceTd"><p>Primitive Type</p></td></tr></tbody></table></div><ul><li><div class="table-wrap"><table class="wrapped confluenceTable"><tbody><tr><td class="confluenceTd"><p>Number</p></td></tr></tbody></table></div><ul><li><div class="table-wrap"><table class="wrapped confluenceTable"><tbody><tr><td class="confluenceTd"><p>DOUBLE</p></td></tr></tbody></table></div><ul><li><div class="table-wrap"><table class="wrapped confluenceTable"><tbody><tr><td class="confluenceTd"><p>FLOAT</p></td></tr></tbody></table></div><ul><li><div class="table-wrap"><table class="wrapped confluenceTable"><tbody><tr><td class="confluenceTd"><p>BIGINT</p></td></tr></tbody></table></div><ul><li><div class="table-wrap"><table class="wrapped confluenceTable"><tbody><tr><td class="confluenceTd"><p>INT</p></td></tr></tbody></table></div><ul><li><div class="table-wrap"><table class="wrapped confluenceTable"><tbody><tr><td class="confluenceTd"><p>SMALLINT</p></td></tr></tbody></table></div><ul><li><div class="table-wrap"><table class="wrapped confluenceTable"><tbody><tr><td class="confluenceTd"><p>TINYINT</p></td></tr></tbody></table></div></li></ul></li></ul></li></ul></li></ul></li><li><div class="table-wrap"><table class="wrapped confluenceTable"><tbody><tr><td class="confluenceTd"><p>STRING</p></td></tr></tbody></table></div></li></ul></li></ul></li><li><div class="table-wrap"><table class="wrapped confluenceTable"><tbody><tr><td class="confluenceTd"><p>BOOLEAN</p></td></tr></tbody></table></div></li></ul></li></ul></li></ul><p>This type hierarchy defines how the types are implicitly converted in the query language. Implicit conversion is allowed for types from child to an ancestor. So when a query expression expects type1 and the data is of type2, type2 is implicitly converted to type1 if type1 is an ancestor of type2 in the type hierarchy. Note that the type hierarchy allows the implicit conversion of STRING to DOUBLE.</p><p>Explicit type conversion can be done using the cast operator as shown in the <a href="https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=82903074#Tutorial-BuiltInFunctions">#Built In Functions</a> section below.</p><h3 id="Tutorial-ComplexTypes">Complex Types</h3><p>Complex Types can be built up from primitive types and other composite types using:</p><ul><li>Structs: the elements within the type can be accessed using the DOT (.) notation. For example, for a column c of type STRUCT {a INT; b INT}, the a field is accessed by the expression c.a</li><li>Maps (key-value tuples): The elements are accessed using ['element name'] notation. For example in a map M comprising of a mapping from 'group' -&gt; gid the gid value can be accessed using M['group']</li><li>Arrays (indexable lists): The elements in the array have to be in the same type. Elements can be accessed using the [n] notation where n is an index (zero-based) into the array. For example, for an array A having the elements ['a', 'b', 'c'], A[1] retruns 'b'.</li></ul><p>Using the primitive types and the constructs for creating complex types, types with arbitrary levels of nesting can be created. For example, a type User may comprise of the following fields:</p><ul><li>gender<span style="color: rgb(34,34,34);">—</span>which is a STRING.</li><li>active<span style="color: rgb(34,34,34);">—</span>which is a BOOLEAN.</li></ul><h3 id="Tutorial-Timestamp">Timestamp</h3><p><span class="confluence-anchor-link conf-macro output-inline" id="Tutorial-timestamp" data-hasbody="false" data-macro-name="anchor"> </span></p><p><br/></p><p><span style="color: rgb(33,33,33);text-decoration: none;">Timestamps have been the source of much confusion, so we try to document the intended semantics of Hive.<br/></span></p><h4 id="Tutorial-Timestamp(&quot;LocalDateTime&quot;semantics)"><span style="color: rgb(67,67,67);text-decoration: none;">Timestamp (&quot;LocalDateTime&quot; semantics)</span></h4><p><span style="color: rgb(33,33,33);text-decoration: none;">Java's &quot;LocalDateTime&quot; timestamps record a date and time as year, month, date, hour, minute, and seconds without a timezone. These timestamps always have those same values regardless of the local time zone.<br/></span></p><p><span style="color: rgb(33,33,33);text-decoration: none;">For example, the timestamp value of &quot;2014-12-12 12:34:56&quot; is decomposed into year, month, day, hour, minute and seconds fields, but with no time zone information available. It does not correspond to any specific instant. It will always be the same value regardless of the local time zone. Unless your application uses UTC consistently, timestamp with local time zone is strongly preferred over timestamp for most applications. When users say an event is at 10:00, it is always in reference to a certain timezone and means a point in time, rather than 10:00 in an arbitrary time zone.</span></p><h4 id="Tutorial-Timestampwithlocaltimezone(&quot;Instant&quot;semantics)"><span style="color: rgb(67,67,67);text-decoration: none;">Timestamp with local time zone (&quot;Instant&quot; semantics)</span></h4><p><span style="color: rgb(33,33,33);text-decoration: none;">Java's &quot;Instant&quot; timestamps define a point in time that remains constant regardless of where the data is read. Thus, the timestamp will be adjusted by the local time zone to match the original point in time.<br/></span></p><p><span style="color: rgb(33,33,33);text-decoration: none;"><br/></span></p><div class="table-wrap"><table class="wrapped confluenceTable"><colgroup><col/><col/><col/></colgroup><tbody><tr><th class="confluenceTh">Type</th><th class="confluenceTh">Value in America/Los_Angeles</th><th class="confluenceTh">Value in America/New_York</th></tr><tr><td class="confluenceTd">timestamp</td><td class="confluenceTd">2014-12-12 12:34:56</td><td class="confluenceTd"><p>2014-12-12 12:34:56</p></td></tr><tr><td colspan="1" class="confluenceTd">timestamp with local time zone</td><td colspan="1" class="confluenceTd">2014-12-12 12:34:56</td><td colspan="1" class="confluenceTd">2014-12-12 15:34:56</td></tr></tbody></table></div><p><span style="color: rgb(33,33,33);text-decoration: none;"><br/></span></p><h4 id="Tutorial-Comparisonswithothertools"><span style="color: rgb(33,33,33);text-decoration: none;">Comparisons with other tools</span></h4><div class="table-wrap"><table class="wrapped confluenceTable"><colgroup><col style="width: 221.0px;"/><col style="width: 90.0px;"/><col style="width: 66.0px;"/><col style="width: 72.0px;"/><col style="width: 83.0px;"/><col style="width: 70.0px;"/><col style="width: 119.0px;"/><col style="width: 80.0px;"/><col style="width: 66.0px;"/><col style="width: 93.0px;"/><col style="width: 98.0px;"/><col/><col style="width: 65.0px;"/></colgroup><tbody><tr><th class="confluenceTh"><br/></th><th class="confluenceTh">SQL 2003</th><th class="confluenceTh">Oracle</th><th class="confluenceTh">Sybase</th><th class="confluenceTh">Postgres</th><th colspan="1" class="confluenceTh">MySQL</th><th class="confluenceTh">Microsoft SQL</th><th class="confluenceTh">IBM DB2</th><th class="confluenceTh">Presto</th><th class="confluenceTh">Snowflake</th><th class="confluenceTh">Hive &gt;= 3.1</th><th colspan="1" class="confluenceTh">Iceberg</th><th class="confluenceTh">Spark</th></tr><tr><td class="confluenceTd">timestamp</td><td class="confluenceTd">Local</td><td class="confluenceTd">Local</td><td class="confluenceTd">Local</td><td class="confluenceTd">Local</td><td colspan="1" class="confluenceTd">Instant</td><td class="confluenceTd">Other</td><td class="confluenceTd">Local</td><td class="confluenceTd">Local</td><td class="confluenceTd">Local</td><td class="confluenceTd">Local</td><td colspan="1" class="confluenceTd">Local</td><td class="confluenceTd">Instant</td></tr><tr><td class="confluenceTd">timestamp with local time zone</td><td class="confluenceTd"><br/></td><td class="confluenceTd">Instant</td><td class="confluenceTd"><br/></td><td class="confluenceTd"><br/></td><td colspan="1" class="confluenceTd"><br/></td><td class="confluenceTd"><br/></td><td class="confluenceTd"><br/></td><td class="confluenceTd"><br/></td><td class="confluenceTd">Instant</td><td class="confluenceTd">Instant</td><td colspan="1" class="confluenceTd"><br/></td><td class="confluenceTd"><br/></td></tr><tr><td class="confluenceTd">timestamp with time zone</td><td class="confluenceTd">Offset</td><td class="confluenceTd">Offset</td><td class="confluenceTd">Offset</td><td class="confluenceTd">Instant</td><td colspan="1" class="confluenceTd"><br/></td><td class="confluenceTd"><br/></td><td class="confluenceTd">Offset</td><td class="confluenceTd">Offset</td><td class="confluenceTd">Offset</td><td class="confluenceTd"><br/></td><td colspan="1" class="confluenceTd">Instant</td><td class="confluenceTd"><br/></td></tr><tr><td class="confluenceTd"><p>timestamp without time zone</p></td><td class="confluenceTd">Local</td><td class="confluenceTd">Local</td><td class="confluenceTd"><br/></td><td class="confluenceTd">Local</td><td colspan="1" class="confluenceTd"><br/></td><td class="confluenceTd"><br/></td><td class="confluenceTd">Local</td><td class="confluenceTd"><br/></td><td class="confluenceTd"><br/></td><td class="confluenceTd"><br/></td><td colspan="1" class="confluenceTd"><br/></td><td class="confluenceTd"><br/></td></tr></tbody></table></div><p>Other definitions:</p><ul><li>Offset = Recording a point in time as well as the time zone offset in the writer's time zone.</li></ul><h2 id="Tutorial-BuiltInOperatorsandFunctions">Built In Operators and Functions</h2><p>The operators and functions listed below are not necessarily up to date. (<a href="LanguageManual%2bUDF.html">Hive Operators and UDFs</a> has more current information.) In <a href="HiveServer2%2bClients.html#HiveServer2Clients-Beeline–NewCommandLineShell">Beeline</a> or the Hive <a href="LanguageManual%2bCli.html">CLI</a>, use these commands to show the latest documentation:</p><div class="code panel pdl conf-macro output-block" style="border-width: 1px;" data-hasbody="true" data-macro-name="code"><div class="codeContent panelContent pdl">
<pre class="syntaxhighlighter-pre" data-syntaxhighlighter-params="brush: java; gutter: false; theme: Default" data-theme="Default">SHOW FUNCTIONS;
DESCRIBE FUNCTION &lt;function_name&gt;;
DESCRIBE FUNCTION EXTENDED &lt;function_name&gt;;
</pre>
</div></div><div class="confluence-information-macro confluence-information-macro-tip conf-macro output-block" data-hasbody="true" data-macro-name="tip"><p class="title">Case-insensitive</p><span class="aui-icon aui-icon-small aui-iconfont-approve confluence-information-macro-icon"> </span><div class="confluence-information-macro-body"><p>All Hive keywords are case-insensitive, including the names of Hive operators and functions.</p></div></div><h3 id="Tutorial-BuiltInOperators">Built In Operators</h3><ul><li><strong>Relational Operators</strong><span style="color: rgb(34,34,34);">—</span>The following operators compare the passed operands and generate a TRUE or FALSE value, depending on whether the comparison between the operands holds or not.</li></ul><div class="table-wrap"><table class="wrapped confluenceTable"><tbody><tr><th class="confluenceTh"><p><strong>Relational Operator</strong></p></th><th class="confluenceTh"><p><strong>Operand types</strong></p></th><th class="confluenceTh"><p><strong>Description</strong></p></th></tr><tr><td class="confluenceTd"><p>A = B</p></td><td class="confluenceTd"><p>all primitive types</p></td><td class="confluenceTd"><p>TRUE if expression A is equivalent to expression B; otherwise FALSE</p></td></tr><tr><td class="confluenceTd"><p>A != B</p></td><td class="confluenceTd"><p>all primitive types</p></td><td class="confluenceTd"><p>TRUE if expression A is <em>not</em> equivalent to expression B; otherwise FALSE</p></td></tr><tr><td class="confluenceTd"><p>A &lt; B</p></td><td class="confluenceTd"><p>all primitive types</p></td><td class="confluenceTd"><p>TRUE if expression A is less than expression B; otherwise FALSE</p></td></tr><tr><td class="confluenceTd"><p>A &lt;= B</p></td><td class="confluenceTd"><p>all primitive types</p></td><td class="confluenceTd"><p>TRUE if expression A is less than or equal to expression B; otherwise FALSE</p></td></tr><tr><td class="confluenceTd"><p>A &gt; B</p></td><td class="confluenceTd"><p>all primitive types</p></td><td class="confluenceTd"><p>TRUE if expression A is greater than expression B] otherwise FALSE</p></td></tr><tr><td class="confluenceTd"><p>A &gt;= B</p></td><td class="confluenceTd"><p>all primitive types</p></td><td class="confluenceTd"><p>TRUE if expression A is greater than or equal to expression B otherwise FALSE</p></td></tr><tr><td class="confluenceTd"><p>A IS NULL</p></td><td class="confluenceTd"><p>all types</p></td><td class="confluenceTd"><p>TRUE if expression A evaluates to NULL otherwise FALSE</p></td></tr><tr><td class="confluenceTd"><p>A IS NOT NULL</p></td><td class="confluenceTd"><p>all types</p></td><td class="confluenceTd"><p>FALSE if expression A evaluates to NULL otherwise TRUE</p></td></tr><tr><td class="confluenceTd"><p>A LIKE B</p></td><td class="confluenceTd"><p>strings</p></td><td class="confluenceTd"><p>TRUE if string A matches the SQL simple regular expression B, otherwise FALSE. The comparison is done character by character. The _ character in B matches any character in A (similar to <strong>.</strong> in posix regular expressions), and the % character in B matches an arbitrary number of characters in A (similar to <strong>.*</strong> in posix regular expressions). For example, <code>'foobar' LIKE 'foo'</code> evaluates to FALSE where as <code>'foobar' LIKE 'foo___'</code> evaluates to TRUE and so does <code>'foobar' LIKE 'foo%'</code>. To escape % use \ (% matches one % character). If the data contains a semicolon, and you want to search for it, it needs to be escaped, <code>columnValue LIKE 'a\;b'</code></p></td></tr><tr><td class="confluenceTd"><p>A RLIKE B</p></td><td class="confluenceTd"><p>strings</p></td><td class="confluenceTd"><p>NULL if A or B is NULL, TRUE if any (possibly empty) substring of A matches the Java regular expression B (see <a href="http://java.sun.com/j2se/1.4.2/docs/api/java/util/regex/Pattern.html" class="external-link" rel="nofollow">Java regular expressions syntax</a>), otherwise FALSE. For example, 'foobar' rlike 'foo' evaluates to TRUE and so does 'foobar' rlike '^f.*r$'.</p></td></tr><tr><td class="confluenceTd"><p>A REGEXP B</p></td><td class="confluenceTd"><p>strings</p></td><td class="confluenceTd"><p>Same as RLIKE</p></td></tr></tbody></table></div><ul><li><strong>Arithmetic Operators</strong><span style="color: rgb(34,34,34);">—</span>The following operators support various common arithmetic operations on the operands. All of them return number types.</li></ul><div class="table-wrap"><table class="wrapped confluenceTable"><tbody><tr><th class="confluenceTh"><p><strong>Arithmetic Operators</strong></p></th><th class="confluenceTh"><p><strong>Operand types</strong></p></th><th class="confluenceTh"><p><strong>Description</strong></p></th></tr><tr><td class="confluenceTd"><p>A + B</p></td><td class="confluenceTd"><p>all number types</p></td><td class="confluenceTd"><p>Gives the result of adding A and B. The type of the result is the same as the common parent(in the type hierarchy) of the types of the operands, for example, since every integer is a float. Therefore, float is a containing type of integer so the + operator on a float and an int will result in a float.</p></td></tr><tr><td class="confluenceTd"><p>A - B</p></td><td class="confluenceTd"><p>all number types</p></td><td class="confluenceTd"><p>Gives the result of subtracting B from A. The type of the result is the same as the common parent(in the type hierarchy) of the types of the operands.</p></td></tr><tr><td class="confluenceTd"><p>A * B</p></td><td class="confluenceTd"><p>all number types</p></td><td class="confluenceTd"><p>Gives the result of multiplying A and B. The type of the result is the same as the common parent(in the type hierarchy) of the types of the operands. Note that if the multiplication causing overflow, you will have to cast one of the operators to a type higher in the type hierarchy.</p></td></tr><tr><td class="confluenceTd"><p>A / B</p></td><td class="confluenceTd"><p>all number types</p></td><td class="confluenceTd"><p>Gives the result of dividing B from A. The type of the result is the same as the common parent(in the type hierarchy) of the types of the operands. If the operands are integer types, then the result is the quotient of the division.</p></td></tr><tr><td class="confluenceTd"><p>A % B</p></td><td class="confluenceTd"><p>all number types</p></td><td class="confluenceTd"><p>Gives the reminder resulting from dividing A by B. The type of the result is the same as the common parent(in the type hierarchy) of the types of the operands.</p></td></tr><tr><td class="confluenceTd"><p>A &amp; B</p></td><td class="confluenceTd"><p>all number types</p></td><td class="confluenceTd"><p>Gives the result of bitwise AND of A and B. The type of the result is the same as the common parent(in the type hierarchy) of the types of the operands.</p></td></tr><tr><td class="confluenceTd"><p>A | B</p></td><td class="confluenceTd"><p>all number types</p></td><td class="confluenceTd"><p>Gives the result of bitwise OR of A and B. The type of the result is the same as the common parent(in the type hierarchy) of the types of the operands.</p></td></tr><tr><td class="confluenceTd"><p>A ^ B</p></td><td class="confluenceTd"><p>all number types</p></td><td class="confluenceTd"><p>Gives the result of bitwise XOR of A and B. The type of the result is the same as the common parent(in the type hierarchy) of the types of the operands.</p></td></tr><tr><td class="confluenceTd"><p>~A</p></td><td class="confluenceTd"><p>all number types</p></td><td class="confluenceTd"><p>Gives the result of bitwise NOT of A. The type of the result is the same as the type of A.</p></td></tr></tbody></table></div><ul><li><strong>Logical Operators</strong> <span style="color: rgb(34,34,34);">—</span> The following operators provide support for creating logical expressions. All of them return boolean TRUE or FALSE depending upon the boolean values of the operands.</li></ul><div class="table-wrap"><table class="wrapped confluenceTable"><tbody><tr><th class="confluenceTh"><p><strong>Logical Operators</strong></p></th><th class="confluenceTh"><p><strong>Operands types</strong></p></th><th class="confluenceTh"><p><strong>Description</strong></p></th></tr><tr><td class="confluenceTd"><p>A AND B</p></td><td class="confluenceTd"><p>boolean</p></td><td class="confluenceTd"><p>TRUE if both A and B are TRUE, otherwise FALSE</p></td></tr><tr><td class="confluenceTd"><p>A &amp;&amp; B</p></td><td class="confluenceTd"><p>boolean</p></td><td class="confluenceTd"><p>Same as A AND B</p></td></tr><tr><td class="confluenceTd"><p>A OR B</p></td><td class="confluenceTd"><p>boolean</p></td><td class="confluenceTd"><p>TRUE if either A or B or both are TRUE, otherwise FALSE</p></td></tr><tr><td class="confluenceTd"><p>A || B</p></td><td class="confluenceTd"><p>boolean</p></td><td class="confluenceTd"><p>Same as A OR B</p></td></tr><tr><td class="confluenceTd"><p>NOT A</p></td><td class="confluenceTd"><p>boolean</p></td><td class="confluenceTd"><p>TRUE if A is FALSE, otherwise FALSE</p></td></tr><tr><td class="confluenceTd"><p>!A</p></td><td class="confluenceTd"><p>boolean</p></td><td class="confluenceTd"><p>Same as NOT A</p></td></tr></tbody></table></div><ul><li><strong>Operators on Complex Types</strong><span style="color: rgb(34,34,34);">—</span>The following operators provide mechanisms to access elements in Complex Types</li></ul><div class="table-wrap"><table class="wrapped confluenceTable"><tbody><tr><th class="confluenceTh"><p><strong>Operator</strong></p></th><th class="confluenceTh"><p><strong>Operand types</strong></p></th><th class="confluenceTh"><p><strong>Description</strong></p></th></tr><tr><td class="confluenceTd"><p>A[n]</p></td><td class="confluenceTd"><p>A is an Array and n is an int</p></td><td class="confluenceTd"><p>returns the nth element in the array A. The first element has index 0, for example, if A is an array comprising of ['foo', 'bar'] then A[0] returns 'foo' and A[1] returns 'bar'</p></td></tr><tr><td class="confluenceTd"><p>M[key]</p></td><td class="confluenceTd"><p>M is a Map&lt;K, V&gt; and key has type K</p></td><td class="confluenceTd"><p>returns the value corresponding to the key in the map for example, if M is a map comprising of <br/>{'f' -&gt; 'foo', 'b' -&gt; 'bar', 'all' -&gt; 'foobar'} then M['all'] returns 'foobar'</p></td></tr><tr><td class="confluenceTd"><p>S.x</p></td><td class="confluenceTd"><p>S is a struct</p></td><td class="confluenceTd"><p>returns the x field of S, for example, for struct foobar {int foo, int bar} foobar.foo returns the integer stored in the foo field of the struct.</p></td></tr></tbody></table></div><h3 id="Tutorial-BuiltInFunctions">Built In Functions</h3><ul><li>Hive supports the following built in functions:<br/><a href="http://svn.apache.org/viewvc/hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/FunctionRegistry.java?view=markup" class="external-link" rel="nofollow">(Function list in source code: FunctionRegistry.java)</a></li></ul><div class="table-wrap"><table class="wrapped confluenceTable"><tbody><tr><th class="confluenceTh"><p><strong>Return Type</strong></p></th><th class="confluenceTh"><p><strong>Function Name (Signature)</strong></p></th><th class="confluenceTh"><p><strong>Description</strong></p></th></tr><tr><td class="confluenceTd"><p>BIGINT</p></td><td class="confluenceTd"><p>round(double a)</p></td><td class="confluenceTd"><p>returns the rounded BIGINT value of the double</p></td></tr><tr><td class="confluenceTd"><p>BIGINT</p></td><td class="confluenceTd"><p>floor(double a)</p></td><td class="confluenceTd"><p>returns the maximum BIGINT value that is equal or less than the double</p></td></tr><tr><td class="confluenceTd"><p>BIGINT</p></td><td class="confluenceTd"><p>ceil(double a)</p></td><td class="confluenceTd"><p>returns the minimum BIGINT value that is equal or greater than the double</p></td></tr><tr><td class="confluenceTd"><p>double</p></td><td class="confluenceTd"><p>rand(), rand(int seed)</p></td><td class="confluenceTd"><p>returns a random number (that changes from row to row). Specifiying the seed will make sure the generated random number sequence is deterministic.</p></td></tr><tr><td class="confluenceTd"><p>string</p></td><td class="confluenceTd"><p>concat(string A, string B,...)</p></td><td class="confluenceTd"><p>returns the string resulting from concatenating B after A. For example, concat('foo', 'bar') results in 'foobar'. This function accepts arbitrary number of arguments and return the concatenation of all of them.</p></td></tr><tr><td class="confluenceTd"><p>string</p></td><td class="confluenceTd"><p>substr(string A, int start)</p></td><td class="confluenceTd"><p>returns the substring of A starting from start position till the end of string A. For example, substr('foobar', 4) results in 'bar'</p></td></tr><tr><td class="confluenceTd"><p>string</p></td><td class="confluenceTd"><p>substr(string A, int start, int length)</p></td><td class="confluenceTd"><p>returns the substring of A starting from start position with the given length, for example, <br/>substr('foobar', 4, 2) results in 'ba'</p></td></tr><tr><td class="confluenceTd"><p>string</p></td><td class="confluenceTd"><p>upper(string A)</p></td><td class="confluenceTd"><p>returns the string resulting from converting all characters of A to upper case, for example, upper('fOoBaR') results in 'FOOBAR'</p></td></tr><tr><td class="confluenceTd"><p>string</p></td><td class="confluenceTd"><p>ucase(string A)</p></td><td class="confluenceTd"><p>Same as upper</p></td></tr><tr><td class="confluenceTd"><p>string</p></td><td class="confluenceTd"><p>lower(string A)</p></td><td class="confluenceTd"><p>returns the string resulting from converting all characters of B to lower case, for example, lower('fOoBaR') results in 'foobar'</p></td></tr><tr><td class="confluenceTd"><p>string</p></td><td class="confluenceTd"><p>lcase(string A)</p></td><td class="confluenceTd"><p>Same as lower</p></td></tr><tr><td class="confluenceTd"><p>string</p></td><td class="confluenceTd"><p>trim(string A)</p></td><td class="confluenceTd"><p>returns the string resulting from trimming spaces from both ends of A, for example, trim(' foobar ') results in 'foobar'</p></td></tr><tr><td class="confluenceTd"><p>string</p></td><td class="confluenceTd"><p>ltrim(string A)</p></td><td class="confluenceTd"><p>returns the string resulting from trimming spaces from the beginning(left hand side) of A. For example, ltrim(' foobar ') results in 'foobar '</p></td></tr><tr><td class="confluenceTd"><p>string</p></td><td class="confluenceTd"><p>rtrim(string A)</p></td><td class="confluenceTd"><p>returns the string resulting from trimming spaces from the end(right hand side) of A. For example, rtrim(' foobar ') results in ' foobar'</p></td></tr><tr><td class="confluenceTd"><p>string</p></td><td class="confluenceTd"><p>regexp_replace(string A, string B, string C)</p></td><td class="confluenceTd"><p>returns the string resulting from replacing all substrings in B that match the Java regular expression syntax(See <a href="http://java.sun.com/j2se/1.4.2/docs/api/java/util/regex/Pattern.html" class="external-link" rel="nofollow">Java regular expressions syntax</a>) with C. For example, regexp_replace('foobar', 'oo|ar', ) returns 'fb'</p></td></tr><tr><td class="confluenceTd"><p>int</p></td><td class="confluenceTd"><p>size(Map&lt;K.V&gt;)</p></td><td class="confluenceTd"><p>returns the number of elements in the map type</p></td></tr><tr><td class="confluenceTd"><p>int</p></td><td class="confluenceTd"><p>size(Array&lt;T&gt;)</p></td><td class="confluenceTd"><p>returns the number of elements in the array type</p></td></tr><tr><td class="confluenceTd"><p><em>value of &lt;type&gt;</em></p></td><td class="confluenceTd"><p>cast(<em>&lt;expr&gt;</em> as <em>&lt;type&gt;</em>)</p></td><td class="confluenceTd"><p>converts the results of the expression expr to &lt;type&gt;, for example, cast('1' as BIGINT) will convert the string '1' to it integral representation. A null is returned if the conversion does not succeed.</p></td></tr><tr><td class="confluenceTd"><p>string</p></td><td class="confluenceTd"><p>from_unixtime(int unixtime)</p></td><td class="confluenceTd"><p>convert the number of seconds from the UNIX epoch (1970-01-01 00:00:00 UTC) to a string representing the timestamp of that moment in the current system time zone in the format of &quot;1970-01-01 00:00:00&quot;</p></td></tr><tr><td class="confluenceTd"><p>string</p></td><td class="confluenceTd"><p>to_date(string timestamp)</p></td><td class="confluenceTd"><p>Return the date part of a timestamp string: to_date(&quot;1970-01-01 00:00:00&quot;) = &quot;1970-01-01&quot;</p></td></tr><tr><td class="confluenceTd"><p>int</p></td><td class="confluenceTd"><p>year(string date)</p></td><td class="confluenceTd"><p>Return the year part of a date or a timestamp string: year(&quot;1970-01-01 00:00:00&quot;) = 1970, year(&quot;1970-01-01&quot;) = 1970</p></td></tr><tr><td class="confluenceTd"><p>int</p></td><td class="confluenceTd"><p>month(string date)</p></td><td class="confluenceTd"><p>Return the month part of a date or a timestamp string: month(&quot;1970-11-01 00:00:00&quot;) = 11, month(&quot;1970-11-01&quot;) = 11</p></td></tr><tr><td class="confluenceTd"><p>int</p></td><td class="confluenceTd"><p>day(string date)</p></td><td class="confluenceTd"><p>Return the day part of a date or a timestamp string: day(&quot;1970-11-01 00:00:00&quot;) = 1, day(&quot;1970-11-01&quot;) = 1</p></td></tr><tr><td class="confluenceTd"><p>string</p></td><td class="confluenceTd"><p>get_json_object(string json_string, string path)</p></td><td class="confluenceTd"><p>Extract json object from a json string based on json path specified, and return json string of the extracted json object. It will return null if the input json string is invalid.</p></td></tr></tbody></table></div><ul><li>The following built in aggregate functions are supported in Hive:</li></ul><div class="table-wrap"><table class="wrapped confluenceTable"><colgroup><col/><col/><col/></colgroup><tbody><tr><th class="confluenceTh"><p><strong>Return Type</strong></p></th><th class="confluenceTh"><p><strong>Aggregation Function Name (Signature)</strong></p></th><th class="confluenceTh"><p><strong>Description</strong></p></th></tr><tr><td class="confluenceTd"><p>BIGINT</p></td><td class="confluenceTd"><p>count(*), count(expr), count(DISTINCT expr[, expr_.])</p></td><td class="confluenceTd"><p>count(*)<span style="color: rgb(34,34,34);">—</span>Returns the total number of retrieved rows, including rows containing NULL values; count(expr)<span style="color: rgb(34,34,34);">—</span>Returns the number of rows for which the supplied expression is non-NULL; count(DISTINCT expr[, expr])<span style="color: rgb(34,34,34);">—</span>Returns the number of rows for which the supplied expression(s) are unique and non-NULL.</p></td></tr><tr><td class="confluenceTd"><p>DOUBLE</p></td><td class="confluenceTd"><p>sum(col), sum(DISTINCT col)</p></td><td class="confluenceTd"><p>returns the sum of the elements in the group or the sum of the distinct values of the column in the group</p></td></tr><tr><td class="confluenceTd"><p>DOUBLE</p></td><td class="confluenceTd"><p>avg(col), avg(DISTINCT col)</p></td><td class="confluenceTd"><p>returns the average of the elements in the group or the average of the distinct values of the column in the group</p></td></tr><tr><td class="confluenceTd"><p>DOUBLE</p></td><td class="confluenceTd"><p>min(col)</p></td><td class="confluenceTd"><p>returns the minimum value of the column in the group</p></td></tr><tr><td class="confluenceTd"><p>DOUBLE</p></td><td class="confluenceTd"><p>max(col)</p></td><td class="confluenceTd"><p>returns the maximum value of the column in the group</p></td></tr></tbody></table></div><h2 id="Tutorial-LanguageCapabilities">Language Capabilities</h2><p><a href="LanguageManual.html">Hive's SQL</a> provides the basic SQL operations. These operations work on tables or partitions. These operations are:</p><ul><li>Ability to filter rows from a table using a WHERE clause.</li><li>Ability to select certain columns from the table using a SELECT clause.</li><li>Ability to do equi-joins between two tables.</li><li>Ability to evaluate aggregations on multiple &quot;group by&quot; columns for the data stored in a table.</li><li>Ability to store the results of a query into another table.</li><li>Ability to download the contents of a table to a local (for example,, nfs) directory.</li><li>Ability to store the results of a query in a hadoop dfs directory.</li><li>Ability to manage tables and partitions (create, drop and alter).</li><li>Ability to plug in custom scripts in the language of choice for custom map/reduce jobs.</li></ul><h1 id="Tutorial-UsageandExamples">Usage and Examples</h1><p><strong>NOTE: Many of the following examples are out of date.  More up to date information can be found in the <a href="LanguageManual.html">LanguageManual</a>.  </strong></p><p>The following examples highlight some salient features of the system. A detailed set of query test cases can be found at <a href="http://svn.apache.org/viewvc/hive/trunk/ql/src/test/queries/clientpositive/" class="external-link" rel="nofollow">Hive Query Test Cases</a> and the corresponding results can be found at <a href="http://svn.apache.org/viewvc/hive/trunk/ql/src/test/results/clientpositive/" class="external-link" rel="nofollow">Query Test Case Results</a>.</p><div class="conf-macro output-block" data-hasbody="true" data-macro-name="toc-zone"><style type="text/css">/*<![CDATA[*/
div.rbtoc1639597156461 {padding: 0px;}
div.rbtoc1639597156461 ul {list-style: disc;margin-left: 0px;}
div.rbtoc1639597156461 li {margin-left: 0px;padding-left: 0px;}

/*]]>*/</style><div class="toc-macro rbtoc1639597156461">
<ul class="toc-indentation">
<li><a href="#Tutorial-Creating,Showing,Altering,andDroppingTables">Creating, Showing, Altering, and Dropping Tables</a></li>
<li><a href="#Tutorial-LoadingData">Loading Data</a></li>
<li><a href="#Tutorial-QueryingandInsertingData">Querying and Inserting Data</a></li>
</ul>
</div><h2 id="Tutorial-Creating,Showing,Altering,andDroppingTables">Creating, Showing, Altering, and Dropping Tables</h2><p>See <a href="LanguageManual%2bDDL.html">Hive Data Definition Language</a> for detailed information about creating, showing, altering, and dropping tables.</p><h3 id="Tutorial-CreatingTables">Creating Tables</h3><p>An example statement that would create the page_view table mentioned above would be like:</p><div class="code panel pdl conf-macro output-block" style="border-width: 1px;" data-hasbody="true" data-macro-name="code"><div class="codeContent panelContent pdl">
<pre class="syntaxhighlighter-pre" data-syntaxhighlighter-params="brush: java; gutter: false; theme: Default" data-theme="Default">    CREATE TABLE page_view(viewTime INT, userid BIGINT,
                    page_url STRING, referrer_url STRING,
                    ip STRING COMMENT 'IP Address of the User')
    COMMENT 'This is the page view table'
    PARTITIONED BY(dt STRING, country STRING)
    STORED AS SEQUENCEFILE;
</pre>
</div></div><p>In this example, the columns of the table are specified with the corresponding types. Comments can be attached both at the column level as well as at the table level. Additionally, the partitioned by clause defines the partitioning columns which are different from the data columns and are actually not stored with the data. When specified in this way, the data in the files is assumed to be delimited with ASCII 001(ctrl-A) as the field delimiter and newline as the row delimiter.</p><p>The field delimiter can be parametrized if the data is not in the above format as illustrated in the following example:</p><div class="code panel pdl conf-macro output-block" style="border-width: 1px;" data-hasbody="true" data-macro-name="code"><div class="codeContent panelContent pdl">
<pre class="syntaxhighlighter-pre" data-syntaxhighlighter-params="brush: java; gutter: false; theme: Default" data-theme="Default">    CREATE TABLE page_view(viewTime INT, userid BIGINT,
                    page_url STRING, referrer_url STRING,
                    ip STRING COMMENT 'IP Address of the User')
    COMMENT 'This is the page view table'
    PARTITIONED BY(dt STRING, country STRING)
    ROW FORMAT DELIMITED
            FIELDS TERMINATED BY '1'
    STORED AS SEQUENCEFILE;
</pre>
</div></div><p>The row delimintor currently cannot be changed since it is not determined by Hive but Hadoop delimiters.</p><p>It is also a good idea to bucket the tables on certain columns so that efficient sampling queries can be executed against the data set. If bucketing is absent, random sampling can still be done on the table but it is not efficient as the query has to scan all the data. The following example illustrates the case of the page_view table that is bucketed on the userid column:</p><div class="code panel pdl conf-macro output-block" style="border-width: 1px;" data-hasbody="true" data-macro-name="code"><div class="codeContent panelContent pdl">
<pre class="syntaxhighlighter-pre" data-syntaxhighlighter-params="brush: java; gutter: false; theme: Default" data-theme="Default">    CREATE TABLE page_view(viewTime INT, userid BIGINT,
                    page_url STRING, referrer_url STRING,
                    ip STRING COMMENT 'IP Address of the User')
    COMMENT 'This is the page view table'
    PARTITIONED BY(dt STRING, country STRING)
    CLUSTERED BY(userid) SORTED BY(viewTime) INTO 32 BUCKETS
    ROW FORMAT DELIMITED
            FIELDS TERMINATED BY '1'
            COLLECTION ITEMS TERMINATED BY '2'
            MAP KEYS TERMINATED BY '3'
    STORED AS SEQUENCEFILE;
</pre>
</div></div><p>In the example above, the table is clustered by a hash function of userid into 32 buckets. Within each bucket the data is sorted in increasing order of viewTime. Such an organization allows the user to do efficient sampling on the clustered column<span style="color: rgb(34,34,34);">&mdash;</span>n this case userid. The sorting property allows internal operators to take advantage of the better-known data structure while evaluating queries with greater efficiency.</p><div class="code panel pdl conf-macro output-block" style="border-width: 1px;" data-hasbody="true" data-macro-name="code"><div class="codeContent panelContent pdl">
<pre class="syntaxhighlighter-pre" data-syntaxhighlighter-params="brush: java; gutter: false; theme: Default" data-theme="Default">    CREATE TABLE page_view(viewTime INT, userid BIGINT,
                    page_url STRING, referrer_url STRING,
                    friends ARRAY&lt;BIGINT&gt;, properties MAP&lt;STRING, STRING&gt;
                    ip STRING COMMENT 'IP Address of the User')
    COMMENT 'This is the page view table'
    PARTITIONED BY(dt STRING, country STRING)
    CLUSTERED BY(userid) SORTED BY(viewTime) INTO 32 BUCKETS
    ROW FORMAT DELIMITED
            FIELDS TERMINATED BY '1'
            COLLECTION ITEMS TERMINATED BY '2'
            MAP KEYS TERMINATED BY '3'
    STORED AS SEQUENCEFILE;
</pre>
</div></div><p>In this example, the columns that comprise of the table row are specified in a similar way as the definition of types. Comments can be attached both at the column level as well as at the table level. Additionally, the partitioned by clause defines the partitioning columns which are different from the data columns and are actually not stored with the data. The CLUSTERED BY clause specifies which column to use for bucketing as well as how many buckets to create. The delimited row format specifies how the rows are stored in the hive table. In the case of the delimited format, this specifies how the fields are terminated, how the items within collections (arrays or maps) are terminated, and how the map keys are terminated. STORED AS SEQUENCEFILE indicates that this data is stored in a binary format (using hadoop SequenceFiles) on hdfs. The values shown for the ROW FORMAT and STORED AS clauses in the above, example represent the system defaults.</p><p>Table names and column names are case insensitive.</p><h3 id="Tutorial-BrowsingTablesandPartitions">Browsing Tables and Partitions</h3><div class="code panel pdl conf-macro output-block" style="border-width: 1px;" data-hasbody="true" data-macro-name="code"><div class="codeContent panelContent pdl">
<pre class="syntaxhighlighter-pre" data-syntaxhighlighter-params="brush: java; gutter: false; theme: Default" data-theme="Default">    SHOW TABLES;
</pre>
</div></div><p>To list existing tables in the warehouse; there are many of these, likely more than you want to browse.</p><div class="code panel pdl conf-macro output-block" style="border-width: 1px;" data-hasbody="true" data-macro-name="code"><div class="codeContent panelContent pdl">
<pre class="syntaxhighlighter-pre" data-syntaxhighlighter-params="brush: java; gutter: false; theme: Default" data-theme="Default">    SHOW TABLES 'page.*';
</pre>
</div></div><p>To list tables with prefix 'page'. The pattern follows Java regular expression syntax (so the period is a wildcard).</p><div class="code panel pdl conf-macro output-block" style="border-width: 1px;" data-hasbody="true" data-macro-name="code"><div class="codeContent panelContent pdl">
<pre class="syntaxhighlighter-pre" data-syntaxhighlighter-params="brush: java; gutter: false; theme: Default" data-theme="Default">    SHOW PARTITIONS page_view;
</pre>
</div></div><p>To list partitions of a table. If the table is not a partitioned table then an error is thrown.</p><div class="code panel pdl conf-macro output-block" style="border-width: 1px;" data-hasbody="true" data-macro-name="code"><div class="codeContent panelContent pdl">
<pre class="syntaxhighlighter-pre" data-syntaxhighlighter-params="brush: java; gutter: false; theme: Default" data-theme="Default">    DESCRIBE page_view;
</pre>
</div></div><p>To list columns and column types of table.</p><div class="code panel pdl conf-macro output-block" style="border-width: 1px;" data-hasbody="true" data-macro-name="code"><div class="codeContent panelContent pdl">
<pre class="syntaxhighlighter-pre" data-syntaxhighlighter-params="brush: java; gutter: false; theme: Default" data-theme="Default">    DESCRIBE EXTENDED page_view;
</pre>
</div></div><p>To list columns and all other properties of table. This prints lot of information and that too not in a pretty format. Usually used for debugging.</p><div class="code panel pdl conf-macro output-block" style="border-width: 1px;" data-hasbody="true" data-macro-name="code"><div class="codeContent panelContent pdl">
<pre class="syntaxhighlighter-pre" data-syntaxhighlighter-params="brush: java; gutter: false; theme: Default" data-theme="Default">   DESCRIBE EXTENDED page_view PARTITION (ds='2008-08-08');
</pre>
</div></div><p>To list columns and all other properties of a partition. This also prints lot of information which is usually used for debugging.</p><h3 id="Tutorial-AlteringTables">Altering Tables</h3><p>To rename existing table to a new name. If a table with new name already exists then an error is returned:</p><div class="code panel pdl conf-macro output-block" style="border-width: 1px;" data-hasbody="true" data-macro-name="code"><div class="codeContent panelContent pdl">
<pre class="syntaxhighlighter-pre" data-syntaxhighlighter-params="brush: java; gutter: false; theme: Default" data-theme="Default">    ALTER TABLE old_table_name RENAME TO new_table_name;
</pre>
</div></div><p>To rename the columns of an existing table. Be sure to use the same column types, and to include an entry for each preexisting column:</p><div class="code panel pdl conf-macro output-block" style="border-width: 1px;" data-hasbody="true" data-macro-name="code"><div class="codeContent panelContent pdl">
<pre class="syntaxhighlighter-pre" data-syntaxhighlighter-params="brush: java; gutter: false; theme: Default" data-theme="Default">    ALTER TABLE old_table_name REPLACE COLUMNS (col1 TYPE, ...);
</pre>
</div></div><p>To add columns to an existing table:</p><div class="code panel pdl conf-macro output-block" style="border-width: 1px;" data-hasbody="true" data-macro-name="code"><div class="codeContent panelContent pdl">
<pre class="syntaxhighlighter-pre" data-syntaxhighlighter-params="brush: java; gutter: false; theme: Default" data-theme="Default">    ALTER TABLE tab1 ADD COLUMNS (c1 INT COMMENT 'a new int column', c2 STRING DEFAULT 'def val');
</pre>
</div></div><p>Note that a change in the schema (such as the adding of the columns), preserves the schema for the old partitions of the table in case it is a partitioned table. All the queries that access these columns and run over the old partitions implicitly return a null value or the specified default values for these columns.</p><p>In the later versions, we can make the behavior of assuming certain values as opposed to throwing an error in case the column is not found in a particular partition configurable.</p><h3 id="Tutorial-DroppingTablesandPartitions">Dropping Tables and Partitions</h3><p>Dropping tables is fairly trivial. A drop on the table would implicitly drop any indexes(this is a future feature) that would have been built on the table. The associated command is:</p><div class="code panel pdl conf-macro output-block" style="border-width: 1px;" data-hasbody="true" data-macro-name="code"><div class="codeContent panelContent pdl">
<pre class="syntaxhighlighter-pre" data-syntaxhighlighter-params="brush: java; gutter: false; theme: Default" data-theme="Default">    DROP TABLE pv_users;
</pre>
</div></div><p>To dropping a partition. Alter the table to drop the partition.</p><div class="code panel pdl conf-macro output-block" style="border-width: 1px;" data-hasbody="true" data-macro-name="code"><div class="codeContent panelContent pdl">
<pre class="syntaxhighlighter-pre" data-syntaxhighlighter-params="brush: java; gutter: false; theme: Default" data-theme="Default">    ALTER TABLE pv_users DROP PARTITION (ds='2008-08-08')
</pre>
</div></div><ul><li>Note that any data for this table or partitions will be dropped and may not be recoverable. *</li></ul><h2 id="Tutorial-LoadingData">Loading Data</h2><p>There are multiple ways to load data into Hive tables. The user can create an external table that points to a specified location within <a href="http://hadoop.apache.org/common/docs/current/hdfs_design.html" class="external-link" rel="nofollow">HDFS</a>. In this particular usage, the user can copy a file into the specified location using the HDFS put or copy commands and create a table pointing to this location with all the relevant row format information. Once this is done, the user can transform the data and insert them into any other Hive table. For example, if the file /tmp/pv_2008-06-08.txt contains comma separated page views served on 2008-06-08, and this needs to be loaded into the page_view table in the appropriate partition, the following sequence of commands can achieve this:</p><div class="code panel pdl conf-macro output-block" style="border-width: 1px;" data-hasbody="true" data-macro-name="code"><div class="codeContent panelContent pdl">
<pre class="syntaxhighlighter-pre" data-syntaxhighlighter-params="brush: java; gutter: false; theme: Default" data-theme="Default">    CREATE EXTERNAL TABLE page_view_stg(viewTime INT, userid BIGINT,
                    page_url STRING, referrer_url STRING,
                    ip STRING COMMENT 'IP Address of the User',
                    country STRING COMMENT 'country of origination')
    COMMENT 'This is the staging page view table'
    ROW FORMAT DELIMITED FIELDS TERMINATED BY '44' LINES TERMINATED BY '12'
    STORED AS TEXTFILE
    LOCATION '/user/data/staging/page_view';

    hadoop dfs -put /tmp/pv_2008-06-08.txt /user/data/staging/page_view

    FROM page_view_stg pvs
    INSERT OVERWRITE TABLE page_view PARTITION(dt='2008-06-08', country='US')
    SELECT pvs.viewTime, pvs.userid, pvs.page_url, pvs.referrer_url, null, null, pvs.ip
    WHERE pvs.country = 'US';
</pre>
</div></div><p>*&nbsp;This code results in an error due to <span style="color: rgb(112,112,112);">LINES TERMINATED BY </span>limitation</p><p><span style="color: rgb(112,112,112);">FAILED: SemanticException 6:67 LINES TERMINATED BY only supports newline '\n' right now. Error encountered near token ''12''</span></p><p><span>See </span>
<span class="jira-issue conf-macro output-block" data-jira-key="HIVE-5999" data-client-id="SINGLE_5aa69414-a9e9-3523-82ec-879b028fb15b_27362061_anonymous" data-hasbody="false" data-macro-name="jira">
                    <a href="https://issues.apache.org/jira/browse/HIVE-5999" class="jira-issue-key"><span class="aui-icon aui-icon-wait issue-placeholder"> </span>HIVE-5999</a>
                            -
            <span class="summary">Getting issue details...</span>
                                                <span class="aui-lozenge aui-lozenge-subtle aui-lozenge-default issue-placeholder">STATUS</span>
                </span>

<span class="jira-issue conf-macro output-block" data-jira-key="HIVE-11996" data-client-id="SINGLE_5aa69414-a9e9-3523-82ec-879b028fb15b_27362061_anonymous" data-hasbody="false" data-macro-name="jira">
                    <a href="https://issues.apache.org/jira/browse/HIVE-11996" class="jira-issue-key"><span class="aui-icon aui-icon-wait issue-placeholder"> </span>HIVE-11996</a>
                            -
            <span class="summary">Getting issue details...</span>
                                                <span class="aui-lozenge aui-lozenge-subtle aui-lozenge-default issue-placeholder">STATUS</span>
                </span>
</p><p><br/></p><p>In the example above, nulls are inserted for the array and map types in the destination tables but potentially these can also come from the external table if the proper row formats are specified.</p><p>This method is useful if there is already legacy data in HDFS on which the user wants to put some metadata so that the data can be queried and manipulated using Hive.</p><p>Additionally, the system also supports syntax that can load the data from a file in the local files system directly into a Hive table where the input data format is the same as the table format. If /tmp/pv_2008-06-08_us.txt already contains the data for US, then we do not need any additional filtering as shown in the previous example. The load in this case can be done using the following syntax:</p><div class="code panel pdl conf-macro output-block" style="border-width: 1px;" data-hasbody="true" data-macro-name="code"><div class="codeContent panelContent pdl">
<pre class="syntaxhighlighter-pre" data-syntaxhighlighter-params="brush: java; gutter: false; theme: Default" data-theme="Default">   LOAD DATA LOCAL INPATH /tmp/pv_2008-06-08_us.txt INTO TABLE page_view PARTITION(date='2008-06-08', country='US')
</pre>
</div></div><p>The path argument can take a directory (in which case all the files in the directory are loaded), a single file name, or a wildcard (in which case all the matching files are uploaded). If the argument is a directory<span style="color: rgb(34,34,34);">, </span>it cannot contain subdirectories. Similarly, the wildcard must match file names only.</p><p>In the case that the input file /tmp/pv_2008-06-08_us.txt is very large, the user may decide to do a parallel load of the data (using tools that are external to Hive). Once the file is in HDFS - the following syntax can be used to load the data into a Hive table:</p><div class="code panel pdl conf-macro output-block" style="border-width: 1px;" data-hasbody="true" data-macro-name="code"><div class="codeContent panelContent pdl">
<pre class="syntaxhighlighter-pre" data-syntaxhighlighter-params="brush: java; gutter: false; theme: Default" data-theme="Default">   LOAD DATA INPATH '/user/data/pv_2008-06-08_us.txt' INTO TABLE page_view PARTITION(date='2008-06-08', country='US')
</pre>
</div></div><p>It is assumed that the array and map fields in the input.txt files are null fields for these examples.</p><p>See <a href="LanguageManual%2bDML.html">Hive Data Manipulation Language</a> for more information about loading data into Hive tables, and see <a href="LanguageManual%2bDDL.html#LanguageManualDDL-ExternalTables">External Tables</a> for another example of creating an external table.</p><h2 id="Tutorial-QueryingandInsertingData">Querying and Inserting Data</h2></div><div class="conf-macro output-block" data-hasbody="true" data-macro-name="toc-zone"><style type="text/css">/*<![CDATA[*/
div.rbtoc1639597156478 {padding: 0px;}
div.rbtoc1639597156478 ul {list-style: disc;margin-left: 0px;}
div.rbtoc1639597156478 li {margin-left: 0px;padding-left: 0px;}

/*]]>*/</style><div class="toc-macro rbtoc1639597156478">
<ul class="toc-indentation">
<li><a href="#Tutorial-SimpleQuery">Simple Query</a></li>
<li><a href="#Tutorial-PartitionBasedQuery">Partition Based Query</a></li>
<li><a href="#Tutorial-Joins">Joins</a></li>
<li><a href="#Tutorial-Aggregations">Aggregations</a></li>
<li><a href="#Tutorial-MultiTable/FileInserts">Multi Table/File Inserts</a></li>
<li><a href="#Tutorial-Dynamic-PartitionInsert">Dynamic-Partition Insert</a></li>
<li><a href="#Tutorial-InsertingintoLocalFiles">Inserting into Local Files</a></li>
<li><a href="#Tutorial-Sampling">Sampling</a></li>
<li><a href="#Tutorial-UnionAll">Union All</a></li>
<li><a href="#Tutorial-ArrayOperations">Array Operations</a></li>
<li><a href="#Tutorial-Map(AssociativeArrays)Operations">Map (Associative Arrays) Operations</a></li>
<li><a href="#Tutorial-CustomMap/ReduceScripts">Custom Map/Reduce Scripts</a></li>
<li><a href="#Tutorial-Co-Groups">Co-Groups</a></li>
</ul>
</div><p>The Hive query operations are documented in <a href="LanguageManual%2bSelect.html">Select</a>, and the insert operations are documented in <a href="LanguageManual%2bDML.html#LanguageManualDML-InsertingdataintoHiveTablesfromqueries">Inserting data into Hive Tables from queries</a> and <a href="LanguageManual%2bDML.html#LanguageManualDML-Writingdataintothefilesystemfromqueries">Writing data into the filesystem from queries</a>.</p><h3 id="Tutorial-SimpleQuery">Simple Query</h3><p>For all the active users, one can use the query of the following form:</p><div class="code panel pdl conf-macro output-block" style="border-width: 1px;" data-hasbody="true" data-macro-name="code"><div class="codeContent panelContent pdl">
<pre class="syntaxhighlighter-pre" data-syntaxhighlighter-params="brush: java; gutter: false; theme: Default" data-theme="Default">    INSERT OVERWRITE TABLE user_active
    SELECT user.*
    FROM user
    WHERE user.active = 1;
</pre>
</div></div><p>Note that unlike SQL, we always insert the results into a table. We will illustrate later how the user can inspect these results and even dump them to a local file. You can also run the following query in&nbsp;<a href="HiveServer2%2bClients.html#HiveServer2Clients-Beeline–NewCommandLineShell">Beeline</a>&nbsp;or the Hive&nbsp;<a href="LanguageManual%2bCli.html">CLI</a>:</p><div class="code panel pdl conf-macro output-block" style="border-width: 1px;" data-hasbody="true" data-macro-name="code"><div class="codeContent panelContent pdl">
<pre class="syntaxhighlighter-pre" data-syntaxhighlighter-params="brush: java; gutter: false; theme: Default" data-theme="Default">    SELECT user.*
    FROM user
    WHERE user.active = 1;
</pre>
</div></div><p>This will be internally rewritten to some temporary file and displayed to the Hive client side.</p><h3 id="Tutorial-PartitionBasedQuery">Partition Based Query</h3><p>What partitions to use in a query is determined automatically by the system on the basis of where clause conditions on partition columns. For example, in order to get all the page_views in the month of 03/2008 referred from domain xyz.com, one could write the following query:</p><div class="code panel pdl conf-macro output-block" style="border-width: 1px;" data-hasbody="true" data-macro-name="code"><div class="codeContent panelContent pdl">
<pre class="syntaxhighlighter-pre" data-syntaxhighlighter-params="brush: java; gutter: false; theme: Default" data-theme="Default">    INSERT OVERWRITE TABLE xyz_com_page_views
    SELECT page_views.*
    FROM page_views
    WHERE page_views.date &gt;= '2008-03-01' AND page_views.date &lt;= '2008-03-31' AND
          page_views.referrer_url like '%xyz.com';
</pre>
</div></div><p>Note that page_views.date is used here because the table (above) was defined with PARTITIONED BY(date DATETIME, country STRING) ; if you name your partition something different, don't expect .date to do what you think!</p><h3 id="Tutorial-Joins">Joins</h3><p>In order to get a demographic breakdown (by gender) of page_view of 2008-03-03 one would need to join the page_view table and the user table on the userid column. This can be accomplished with a join as shown in the following query:</p><div class="code panel pdl conf-macro output-block" style="border-width: 1px;" data-hasbody="true" data-macro-name="code"><div class="codeContent panelContent pdl">
<pre class="syntaxhighlighter-pre" data-syntaxhighlighter-params="brush: java; gutter: false; theme: Default" data-theme="Default">    INSERT OVERWRITE TABLE pv_users
    SELECT pv.*, u.gender, u.age
    FROM user u JOIN page_view pv ON (pv.userid = u.id)
    WHERE pv.date = '2008-03-03';
</pre>
</div></div><p>In order to do outer joins the user can qualify the join with LEFT OUTER, RIGHT OUTER or FULL OUTER keywords in order to indicate the kind of outer join (left preserved, right preserved or both sides preserved). For example, in order to do a full outer join in the query above, the corresponding syntax would look like the following query:</p><div class="code panel pdl conf-macro output-block" style="border-width: 1px;" data-hasbody="true" data-macro-name="code"><div class="codeContent panelContent pdl">
<pre class="syntaxhighlighter-pre" data-syntaxhighlighter-params="brush: java; gutter: false; theme: Default" data-theme="Default">    INSERT OVERWRITE TABLE pv_users
    SELECT pv.*, u.gender, u.age
    FROM user u FULL OUTER JOIN page_view pv ON (pv.userid = u.id)
    WHERE pv.date = '2008-03-03';
</pre>
</div></div><p>In order check the existence of a key in another table, the user can use LEFT SEMI JOIN as illustrated by the following example.</p><div class="code panel pdl conf-macro output-block" style="border-width: 1px;" data-hasbody="true" data-macro-name="code"><div class="codeContent panelContent pdl">
<pre class="syntaxhighlighter-pre" data-syntaxhighlighter-params="brush: java; gutter: false; theme: Default" data-theme="Default">    INSERT OVERWRITE TABLE pv_users
    SELECT u.*
    FROM user u LEFT SEMI JOIN page_view pv ON (pv.userid = u.id)
    WHERE pv.date = '2008-03-03';
</pre>
</div></div><p>In order to join more than one tables, the user can use the following syntax:</p><div class="code panel pdl conf-macro output-block" style="border-width: 1px;" data-hasbody="true" data-macro-name="code"><div class="codeContent panelContent pdl">
<pre class="syntaxhighlighter-pre" data-syntaxhighlighter-params="brush: java; gutter: false; theme: Default" data-theme="Default">    INSERT OVERWRITE TABLE pv_friends
    SELECT pv.*, u.gender, u.age, f.friends
    FROM page_view pv JOIN user u ON (pv.userid = u.id) JOIN friend_list f ON (u.id = f.uid)
    WHERE pv.date = '2008-03-03';
</pre>
</div></div><h3 id="Tutorial-Aggregations">Aggregations</h3><p>In order to count the number of distinct users by gender one could write the following query:</p><div class="code panel pdl conf-macro output-block" style="border-width: 1px;" data-hasbody="true" data-macro-name="code"><div class="codeContent panelContent pdl">
<pre class="syntaxhighlighter-pre" data-syntaxhighlighter-params="brush: java; gutter: false; theme: Default" data-theme="Default">    INSERT OVERWRITE TABLE pv_gender_sum
    SELECT pv_users.gender, count (DISTINCT pv_users.userid)
    FROM pv_users
    GROUP BY pv_users.gender;
</pre>
</div></div><p>Multiple aggregations can be done at the same time, however, no two aggregations can have different DISTINCT columns .e.g while the following is possible</p><div class="code panel pdl conf-macro output-block" style="border-width: 1px;" data-hasbody="true" data-macro-name="code"><div class="codeContent panelContent pdl">
<pre class="syntaxhighlighter-pre" data-syntaxhighlighter-params="brush: java; gutter: false; theme: Default" data-theme="Default">    INSERT OVERWRITE TABLE pv_gender_agg
    SELECT pv_users.gender, count(DISTINCT pv_users.userid), count(*), sum(DISTINCT pv_users.userid)
    FROM pv_users
    GROUP BY pv_users.gender;
</pre>
</div></div><p>however, the following query is not allowed</p><div class="code panel pdl conf-macro output-block" style="border-width: 1px;" data-hasbody="true" data-macro-name="code"><div class="codeContent panelContent pdl">
<pre class="syntaxhighlighter-pre" data-syntaxhighlighter-params="brush: java; gutter: false; theme: Default" data-theme="Default">    INSERT OVERWRITE TABLE pv_gender_agg
    SELECT pv_users.gender, count(DISTINCT pv_users.userid), count(DISTINCT pv_users.ip)
    FROM pv_users
    GROUP BY pv_users.gender;
</pre>
</div></div><h3 id="Tutorial-MultiTable/FileInserts">Multi Table/File Inserts</h3><p>The output of the aggregations or simple selects can be further sent into multiple tables or even to hadoop dfs files (which can then be manipulated using hdfs utilities). For example, if along with the gender breakdown, one needed to find the breakdown of unique page views by age, one could accomplish that with the following query:</p><div class="code panel pdl conf-macro output-block" style="border-width: 1px;" data-hasbody="true" data-macro-name="code"><div class="codeContent panelContent pdl">
<pre class="syntaxhighlighter-pre" data-syntaxhighlighter-params="brush: java; gutter: false; theme: Default" data-theme="Default">    FROM pv_users
    INSERT OVERWRITE TABLE pv_gender_sum
        SELECT pv_users.gender, count_distinct(pv_users.userid)
        GROUP BY pv_users.gender

    INSERT OVERWRITE DIRECTORY '/user/data/tmp/pv_age_sum'
        SELECT pv_users.age, count_distinct(pv_users.userid)
        GROUP BY pv_users.age;
</pre>
</div></div><p>The first insert clause sends the results of the first group by to a Hive table while the second one sends the results to a hadoop dfs files.</p><h3 id="Tutorial-Dynamic-PartitionInsert">Dynamic-Partition Insert</h3><p>In the previous examples, the user has to know which partition to insert into and only one partition can be inserted in one insert statement. If you want to load into multiple partitions, you have to use multi-insert statement as illustrated below.</p><div class="code panel pdl conf-macro output-block" style="border-width: 1px;" data-hasbody="true" data-macro-name="code"><div class="codeContent panelContent pdl">
<pre class="syntaxhighlighter-pre" data-syntaxhighlighter-params="brush: java; gutter: false; theme: Default" data-theme="Default">    FROM page_view_stg pvs
    INSERT OVERWRITE TABLE page_view PARTITION(dt='2008-06-08', country='US')
           SELECT pvs.viewTime, pvs.userid, pvs.page_url, pvs.referrer_url, null, null, pvs.ip WHERE pvs.country = 'US'
    INSERT OVERWRITE TABLE page_view PARTITION(dt='2008-06-08', country='CA')
           SELECT pvs.viewTime, pvs.userid, pvs.page_url, pvs.referrer_url, null, null, pvs.ip WHERE pvs.country = 'CA'
    INSERT OVERWRITE TABLE page_view PARTITION(dt='2008-06-08', country='UK')
           SELECT pvs.viewTime, pvs.userid, pvs.page_url, pvs.referrer_url, null, null, pvs.ip WHERE pvs.country = 'UK';
</pre>
</div></div><p>In order to load data into all country partitions in a particular day, you have to add an insert statement for each country in the input data. This is very inconvenient since you have to have the priori knowledge of the list of countries exist in the input data and create the partitions beforehand. If the list changed for another day, you have to modify your insert DML as well as the partition creation DDLs. It is also inefficient since each insert statement may be turned into a MapReduce Job.</p><p><em><a href="LanguageManual%2bDML.html#LanguageManualDML-DynamicPartitionInserts">Dynamic-partition insert</a></em> (or multi-partition insert) is designed to solve this problem by dynamically determining which partitions should be created and populated while scanning the input table. This is a newly added feature that is only available from version 0.6.0. In the dynamic partition insert, the input column values are evaluated to determine which partition this row should be inserted into. If that partition has not been created, it will create that partition automatically. Using this feature you need only one insert statement to create and populate all necessary partitions. In addition, since there is only one insert statement, there is only one corresponding MapReduce job. This significantly improves performance and reduce the Hadoop cluster workload comparing to the multiple insert case.</p><p>Below is an example of loading data to all country partitions using one insert statement:</p><div class="code panel pdl conf-macro output-block" style="border-width: 1px;" data-hasbody="true" data-macro-name="code"><div class="codeContent panelContent pdl">
<pre class="syntaxhighlighter-pre" data-syntaxhighlighter-params="brush: java; gutter: false; theme: Default" data-theme="Default">    FROM page_view_stg pvs
    INSERT OVERWRITE TABLE page_view PARTITION(dt='2008-06-08', country)
           SELECT pvs.viewTime, pvs.userid, pvs.page_url, pvs.referrer_url, null, null, pvs.ip, pvs.country
</pre>
</div></div><p>There are several syntactic differences from the multi-insert statement:</p><ul><li>country appears in the PARTITION specification, but with no value associated. In this case, country is a <em>dynamic partition column</em>. On the other hand, ds has a value associated with it, which means it is a <em>static partition column</em>. If a column is dynamic partition column, its value will be coming from the input column. Currently we only allow dynamic partition columns to be the last column(s) in the partition clause because the partition column order indicates its hierarchical order (meaning dt is the root partition, and country is the child partition). You cannot specify a partition clause with (dt, country='US') because that means you need to update all partitions with any date and its country sub-partition is 'US'.</li><li>An additional pvs.country column is added in the select statement. This is the corresponding input column for the dynamic partition column. Note that you do not need to add an input column for the static partition column because its value is already known in the PARTITION clause. Note that the dynamic partition values are selected by ordering, not name, and taken as the last columns from the select clause.</li></ul><p>Semantics of the dynamic partition insert statement:</p><ul><li>When there are already non-empty partitions exists for the dynamic partition columns, (for example, country='CA' exists under some ds root partition), it will be overwritten if the dynamic partition insert saw the same value (say 'CA') in the input data. This is in line with the 'insert overwrite' semantics. However, if the partition value 'CA' does not appear in the input data, the existing partition will not be overwritten.</li><li>Since a Hive partition corresponds to a directory in HDFS, the partition value has to conform to the HDFS path format (URI in Java). Any character having a special meaning in URI (for example, '%', ':', '/', '#') will be escaped with '%' followed by 2 bytes of its ASCII value.</li><li>If the input column is a type different than STRING, its value will be first converted to STRING to be used to construct the HDFS path.</li><li>If the input column value is NULL or empty string, the row will be put into a special partition, whose name is controlled by the hive parameter hive.exec.default.partition.name. The default value is <code>HIVE_DEFAULT_PARTITION</code>{<em>}</em>. Basically this partition will contain all &quot;bad&quot; rows whose value are not valid partition names. The caveat of this approach is that the bad value will be lost and is replaced by <code>HIVE_DEFAULT_PARTITION</code>{<em>}</em> if you select them Hive. JIRA HIVE-1309 is a solution to let user specify &quot;bad file&quot; to retain the input partition column values as well.</li><li>Dynamic partition insert could potentially be a resource hog in that it could generate a large number of partitions in a short time. To get yourself buckled, we define three parameters:<ul><li><strong>hive.exec.max.dynamic.partitions.pernode</strong> (default value being 100) is the maximum dynamic partitions that can be created by each mapper or reducer. If one mapper or reducer created more than that the threshold, a fatal error will be raised from the mapper/reducer (through counter) and the whole job will be killed.</li><li><strong>hive.exec.max.dynamic.partitions</strong> (default value being 1000) is the total number of dynamic partitions could be created by one DML. If each mapper/reducer did not exceed the limit but the total number of dynamic partitions does, then an exception is raised at the end of the job before the intermediate data are moved to the final destination.</li><li><strong>hive.exec.max.created.files</strong> (default value being 100000) is the maximum total number of files created by all mappers and reducers. This is implemented by updating a Hadoop counter by each mapper/reducer whenever a new file is created. If the total number is exceeding hive.exec.max.created.files, a fatal error will be thrown and the job will be killed.</li></ul></li></ul><ul><li>Another situation we want to protect against dynamic partition insert is that the user may accidentally specify all partitions to be dynamic partitions without specifying one static partition, while the original intention is to just overwrite the sub-partitions of one root partition. We define another parameter hive.exec.dynamic.partition.mode=strict to prevent the all-dynamic partition case. In the strict mode, you have to specify at least one static partition. The default mode is strict. In addition, we have a parameter hive.exec.dynamic.partition=true/false to control whether to allow dynamic partition at all. The default value is false prior to Hive 0.9.0 and true in Hive 0.9.0 and later.</li><li>In Hive 0.6, dynamic partition insert does not work with hive.merge.mapfiles=true or hive.merge.mapredfiles=true, so it internally turns off the merge parameters. Merging files in dynamic partition inserts are supported in Hive 0.7 (see JIRA HIVE-1307 for details).</li></ul><p>Troubleshooting and best practices:</p><ul><li><p>As stated above, there are too many dynamic partitions created by a particular mapper/reducer, a fatal error could be raised and the job will be killed. The error message looks something like:</p><div class="code panel pdl conf-macro output-block" style="border-width: 1px;" data-hasbody="true" data-macro-name="code"><div class="codeContent panelContent pdl">
<pre class="syntaxhighlighter-pre" data-syntaxhighlighter-params="brush: java; gutter: false; theme: Default" data-theme="Default">    beeline&gt; set hive.exec.dynamic.partition.mode=nonstrict;
    beeline&gt; FROM page_view_stg pvs
          INSERT OVERWRITE TABLE page_view PARTITION(dt, country)
                 SELECT pvs.viewTime, pvs.userid, pvs.page_url, pvs.referrer_url, null, null, pvs.ip,
                        from_unixtimestamp(pvs.viewTime, 'yyyy-MM-dd') ds, pvs.country;
...
2010-05-07 11:10:19,816 Stage-1 map = 0%,  reduce = 0%
[Fatal Error] Operator FS_28 (id=41): fatal error. Killing the job.
Ended Job = job_201005052204_28178 with errors
...
</pre>
</div></div><p>The problem of this that one mapper will take a random set of rows and it is very likely that the number of distinct (dt, country) pairs will exceed the limit of hive.exec.max.dynamic.partitions.pernode. One way around it is to group the rows by the dynamic partition columns in the mapper and distribute them to the reducers where the dynamic partitions will be created. In this case the number of distinct dynamic partitions will be significantly reduced. The above example query could be rewritten to:</p><div class="code panel pdl conf-macro output-block" style="border-width: 1px;" data-hasbody="true" data-macro-name="code"><div class="codeContent panelContent pdl">
<pre class="syntaxhighlighter-pre" data-syntaxhighlighter-params="brush: java; gutter: false; theme: Default" data-theme="Default">    beeline&gt; set hive.exec.dynamic.partition.mode=nonstrict;
    beeline&gt; FROM page_view_stg pvs
          INSERT OVERWRITE TABLE page_view PARTITION(dt, country)
                 SELECT pvs.viewTime, pvs.userid, pvs.page_url, pvs.referrer_url, null, null, pvs.ip,
                        from_unixtimestamp(pvs.viewTime, 'yyyy-MM-dd') ds, pvs.country
                 DISTRIBUTE BY ds, country;
</pre>
</div></div><p>This query will generate a MapReduce job rather than Map-only job. The SELECT-clause will be converted to a plan to the mappers and the output will be distributed to the reducers based on the value of (ds, country) pairs. The INSERT-clause will be converted to the plan in the reducer which writes to the dynamic partitions.</p></li></ul><p>Additional documentation:</p><ul><li><a href="DynamicPartitions.html">Design Document for Dynamic Partitions</a><ul><li><a href="https://issues.apache.org/jira/secure/attachment/12437909/dp_design.txt" class="external-link" rel="nofollow">Original design doc</a></li><li><a href="https://issues.apache.org/jira/browse/HIVE-936" class="external-link" rel="nofollow">HIVE-936</a></li></ul></li><li><a href="LanguageManual%2bDML.html#LanguageManualDML-DynamicPartitionInserts">Hive DML: Dynamic Partition Inserts</a></li><li><a href="HCatalog%2bDynamicPartitions.html">HCatalog Dynamic Partitioning</a><ul><li><a href="HCatalog%2bDynamicPartitions.html#HCatalogDynamicPartitions-UsagewithPig">Usage with Pig</a></li><li><a href="HCatalog%2bDynamicPartitions.html#HCatalogDynamicPartitions-UsagefromMapReduce">Usage from MapReduce</a></li></ul></li></ul><h3 id="Tutorial-InsertingintoLocalFiles">Inserting into Local Files</h3><p>In certain situations you would want to write the output into a local file so that you could load it into an excel spreadsheet. This can be accomplished with the following command:</p><div class="code panel pdl conf-macro output-block" style="border-width: 1px;" data-hasbody="true" data-macro-name="code"><div class="codeContent panelContent pdl">
<pre class="syntaxhighlighter-pre" data-syntaxhighlighter-params="brush: java; gutter: false; theme: Default" data-theme="Default">    INSERT OVERWRITE LOCAL DIRECTORY '/tmp/pv_gender_sum'
    SELECT pv_gender_sum.*
    FROM pv_gender_sum;
</pre>
</div></div><h3 id="Tutorial-Sampling">Sampling</h3><p>The sampling clause allows the users to write queries for samples of the data instead of the whole table. Currently the sampling is done on the columns that are specified in the CLUSTERED BY clause of the CREATE TABLE statement. In the following example we choose 3rd bucket out of the 32 buckets of the pv_gender_sum table:</p><div class="code panel pdl conf-macro output-block" style="border-width: 1px;" data-hasbody="true" data-macro-name="code"><div class="codeContent panelContent pdl">
<pre class="syntaxhighlighter-pre" data-syntaxhighlighter-params="brush: java; gutter: false; theme: Default" data-theme="Default">    INSERT OVERWRITE TABLE pv_gender_sum_sample
    SELECT pv_gender_sum.*
    FROM pv_gender_sum TABLESAMPLE(BUCKET 3 OUT OF 32);
</pre>
</div></div><p>In general the TABLESAMPLE syntax looks like:</p><div class="code panel pdl conf-macro output-block" style="border-width: 1px;" data-hasbody="true" data-macro-name="code"><div class="codeContent panelContent pdl">
<pre class="syntaxhighlighter-pre" data-syntaxhighlighter-params="brush: java; gutter: false; theme: Default" data-theme="Default">    TABLESAMPLE(BUCKET x OUT OF y)
</pre>
</div></div><p>y has to be a multiple or divisor of the number of buckets in that table as specified at the table creation time. The buckets chosen are determined if bucket_number module y is equal to x. So in the above example the following tablesample clause</p><div class="code panel pdl conf-macro output-block" style="border-width: 1px;" data-hasbody="true" data-macro-name="code"><div class="codeContent panelContent pdl">
<pre class="syntaxhighlighter-pre" data-syntaxhighlighter-params="brush: java; gutter: false; theme: Default" data-theme="Default">      TABLESAMPLE(BUCKET 3 OUT OF 16)
</pre>
</div></div><p>would pick out the 3rd and 19th buckets. The buckets are numbered starting from 0.</p><p>On the other hand the tablesample clause</p><div class="code panel pdl conf-macro output-block" style="border-width: 1px;" data-hasbody="true" data-macro-name="code"><div class="codeContent panelContent pdl">
<pre class="syntaxhighlighter-pre" data-syntaxhighlighter-params="brush: java; gutter: false; theme: Default" data-theme="Default">     TABLESAMPLE(BUCKET 3 OUT OF 64 ON userid)
</pre>
</div></div><p>would pick out half of the 3rd bucket.</p><h3 id="Tutorial-UnionAll">Union All</h3><p>The language also supports union all, for example, if we suppose there are two different tables that track which user has published a video and which user has published a comment, the following query joins the results of a union all with the user table to create a single annotated stream for all the video publishing and comment publishing events:</p><div class="code panel pdl conf-macro output-block" style="border-width: 1px;" data-hasbody="true" data-macro-name="code"><div class="codeContent panelContent pdl">
<pre class="syntaxhighlighter-pre" data-syntaxhighlighter-params="brush: java; gutter: false; theme: Default" data-theme="Default">    INSERT OVERWRITE TABLE actions_users
    SELECT u.id, actions.date
    FROM (
        SELECT av.uid AS uid
        FROM action_video av
        WHERE av.date = '2008-06-03'

        UNION ALL

        SELECT ac.uid AS uid
        FROM action_comment ac
        WHERE ac.date = '2008-06-03'
        ) actions JOIN users u ON(u.id = actions.uid);
</pre>
</div></div><h3 id="Tutorial-ArrayOperations">Array Operations</h3><p>Array columns in tables can be as follows:</p><div class="code panel pdl conf-macro output-block" style="border-width: 1px;" data-hasbody="true" data-macro-name="code"><div class="codeContent panelContent pdl">
<pre class="syntaxhighlighter-pre" data-syntaxhighlighter-params="brush: sql; gutter: false; theme: Default" data-theme="Default">CREATE TABLE array_table (int_array_column ARRAY&lt;INT&gt;);</pre>
</div></div><p>Assuming that pv.friends is of the type ARRAY&lt;INT&gt; (i.e. it is an array of integers), the user can get a specific element in the array by its index as shown in the following command:</p><div class="code panel pdl conf-macro output-block" style="border-width: 1px;" data-hasbody="true" data-macro-name="code"><div class="codeContent panelContent pdl">
<pre class="syntaxhighlighter-pre" data-syntaxhighlighter-params="brush: java; gutter: false; theme: Default" data-theme="Default">    SELECT pv.friends[2]
    FROM page_views pv;
</pre>
</div></div><p>The select expression gets the third item in the pv.friends array.</p><p>The user can also get the length of the array using the size function as shown below:</p><div class="code panel pdl conf-macro output-block" style="border-width: 1px;" data-hasbody="true" data-macro-name="code"><div class="codeContent panelContent pdl">
<pre class="syntaxhighlighter-pre" data-syntaxhighlighter-params="brush: java; gutter: false; theme: Default" data-theme="Default">   SELECT pv.userid, size(pv.friends)
   FROM page_view pv;
</pre>
</div></div><h3 id="Tutorial-Map(AssociativeArrays)Operations">Map (Associative Arrays) Operations</h3><p>Maps provide collections similar to associative arrays. Such structures can only be created programmatically currently. We will be extending this soon. For the purpose of the current example assume that pv.properties is of the type map&lt;String, String&gt; i.e. it is an associative array from strings to string. Accordingly, the following query:</p><div class="code panel pdl conf-macro output-block" style="border-width: 1px;" data-hasbody="true" data-macro-name="code"><div class="codeContent panelContent pdl">
<pre class="syntaxhighlighter-pre" data-syntaxhighlighter-params="brush: java; gutter: false; theme: Default" data-theme="Default">    INSERT OVERWRITE page_views_map
    SELECT pv.userid, pv.properties['page type']
    FROM page_views pv;
</pre>
</div></div><p>can be used to select the 'page_type' property from the page_views table.</p><p>Similar to arrays, the size function can also be used to get the number of elements in a map as shown in the following query:</p><div class="code panel pdl conf-macro output-block" style="border-width: 1px;" data-hasbody="true" data-macro-name="code"><div class="codeContent panelContent pdl">
<pre class="syntaxhighlighter-pre" data-syntaxhighlighter-params="brush: java; gutter: false; theme: Default" data-theme="Default">   SELECT size(pv.properties)
   FROM page_view pv;
</pre>
</div></div><h3 id="Tutorial-CustomMap/ReduceScripts">Custom Map/Reduce Scripts</h3><p>Users can also plug in their own custom mappers and reducers in the data stream by using features natively supported in the Hive language. for example, in order to run a custom mapper script - map_script - and a custom reducer script - reduce_script - the user can issue the following command which uses the TRANSFORM clause to embed the mapper and the reducer scripts.</p><p>Note that columns will be transformed to string and delimited by TAB before feeding to the user script, and the standard output of the user script will be treated as TAB-separated string columns. User scripts can output debug information to standard error which will be shown on the task detail page on hadoop.</p><div class="code panel pdl conf-macro output-block" style="border-width: 1px;" data-hasbody="true" data-macro-name="code"><div class="codeContent panelContent pdl">
<pre class="syntaxhighlighter-pre" data-syntaxhighlighter-params="brush: java; gutter: false; theme: Default" data-theme="Default">   FROM (
        FROM pv_users
        MAP pv_users.userid, pv_users.date
        USING 'map_script'
        AS dt, uid
        CLUSTER BY dt) map_output

    INSERT OVERWRITE TABLE pv_users_reduced
        REDUCE map_output.dt, map_output.uid
        USING 'reduce_script'
        AS date, count;
</pre>
</div></div><p>Sample map script (weekday_mapper.py )</p><div class="code panel pdl conf-macro output-block" style="border-width: 1px;" data-hasbody="true" data-macro-name="code"><div class="codeContent panelContent pdl">
<pre class="syntaxhighlighter-pre" data-syntaxhighlighter-params="brush: java; gutter: false; theme: Default" data-theme="Default">import sys
import datetime

for line in sys.stdin:
  line = line.strip()
  userid, unixtime = line.split('\t')
  weekday = datetime.datetime.fromtimestamp(float(unixtime)).isoweekday()
  print ','.join([userid, str(weekday)])
</pre>
</div></div><p>Of course, both MAP and REDUCE are &quot;syntactic sugar&quot; for the more general select transform. The inner query could also have been written as such:</p><div class="code panel pdl conf-macro output-block" style="border-width: 1px;" data-hasbody="true" data-macro-name="code"><div class="codeContent panelContent pdl">
<pre class="syntaxhighlighter-pre" data-syntaxhighlighter-params="brush: java; gutter: false; theme: Default" data-theme="Default">    SELECT TRANSFORM(pv_users.userid, pv_users.date) USING 'map_script' AS dt, uid CLUSTER BY dt FROM pv_users;
</pre>
</div></div><p>Schema-less map/reduce: If there is no &quot;AS&quot; clause after &quot;USING map_script&quot;, Hive assumes the output of the script contains 2 parts: key which is before the first tab, and value which is the rest after the first tab. Note that this is different from specifying &quot;AS key, value&quot; because in that case value will only contains the portion between the first tab and the second tab if there are multiple tabs.</p><p>In this way, we allow users to migrate old map/reduce scripts without knowing the schema of the map output. User still needs to know the reduce output schema because that has to match what is in the table that we are inserting to.</p><div class="code panel pdl conf-macro output-block" style="border-width: 1px;" data-hasbody="true" data-macro-name="code"><div class="codeContent panelContent pdl">
<pre class="syntaxhighlighter-pre" data-syntaxhighlighter-params="brush: java; gutter: false; theme: Default" data-theme="Default">    FROM (
        FROM pv_users
        MAP pv_users.userid, pv_users.date
        USING 'map_script'
        CLUSTER BY key) map_output

    INSERT OVERWRITE TABLE pv_users_reduced

        REDUCE map_output.dt, map_output.uid
        USING 'reduce_script'
        AS date, count;
</pre>
</div></div><p>Distribute By and Sort By: Instead of specifying &quot;cluster by&quot;, the user can specify &quot;distribute by&quot; and &quot;sort by&quot;, so the partition columns and sort columns can be different. The usual case is that the partition columns are a prefix of sort columns, but that is not required.</p><div class="code panel pdl conf-macro output-block" style="border-width: 1px;" data-hasbody="true" data-macro-name="code"><div class="codeContent panelContent pdl">
<pre class="syntaxhighlighter-pre" data-syntaxhighlighter-params="brush: java; gutter: false; theme: Default" data-theme="Default">    FROM (
        FROM pv_users
        MAP pv_users.userid, pv_users.date
        USING 'map_script'
        AS c1, c2, c3
        DISTRIBUTE BY c2
        SORT BY c2, c1) map_output

    INSERT OVERWRITE TABLE pv_users_reduced

        REDUCE map_output.c1, map_output.c2, map_output.c3
        USING 'reduce_script'
        AS date, count;
</pre>
</div></div><h3 id="Tutorial-Co-Groups">Co-Groups</h3><p>Amongst the user community using map/reduce, cogroup is a fairly common operation wherein the data from multiple tables are sent to a custom reducer such that the rows are grouped by the values of certain columns on the tables. With the UNION ALL operator and the CLUSTER BY specification, this can be achieved in the Hive query language in the following way. Suppose we wanted to cogroup the rows from the actions_video and action_comments table on the uid column and send them to the 'reduce_script' custom reducer, the following syntax can be used by the user:</p><div class="code panel pdl conf-macro output-block" style="border-width: 1px;" data-hasbody="true" data-macro-name="code"><div class="codeContent panelContent pdl">
<pre class="syntaxhighlighter-pre" data-syntaxhighlighter-params="brush: java; gutter: false; theme: Default" data-theme="Default">   FROM (
        FROM (
                FROM action_video av
                SELECT av.uid AS uid, av.id AS id, av.date AS date

               UNION ALL

                FROM action_comment ac
                SELECT ac.uid AS uid, ac.id AS id, ac.date AS date
        ) union_actions
        SELECT union_actions.uid, union_actions.id, union_actions.date
        CLUSTER BY union_actions.uid) map

    INSERT OVERWRITE TABLE actions_reduced
        SELECT TRANSFORM(map.uid, map.id, map.date) USING 'reduce_script' AS (uid, id, reduced_val);
</pre>
</div></div></div><p><br/></p><p><br/></p>

                
        
    
        </div>

                        
    



<div id="labels-section" class="pageSection group">
    <div class="labels-section-content content-column" entityid="27362061" entitytype="page">
	<div class="labels-content">
		
    <ul class="label-list label-list-right ">
            <li class="no-labels-message">
            No labels
        </li>
            </ul>

    </div>
</div>
</div>
        
		
            




            
        








                        
    
<div id="comments-section" class="pageSection group">
        
    



</div>
        


                
    
            
</div>

    

    




    
    

    
    
    


    
<div id="space-tools-web-items" class="hidden">
                <div data-label="Overview" data-href="/confluence/spaces/viewspacesummary.action?key=Hive">Overview</div>
            <div data-label="Content Tools" data-href="/confluence/pages/reorderpages.action?key=Hive">Content Tools</div>
            <div data-label="Apps" data-href="/confluence/spaces/snippeterrors.action?key=Hive">Apps</div>
    </div>
        



            </div><!-- \#main -->
            
    
    
        
            
            

<div id="footer" role="contentinfo">
    <section class="footer-body">

                                                            <p class="license license-opensource">
                    Powered by a free <b>Atlassian Confluence Open Source Project License</b> granted to Apache Software Foundation. <a href="https://www.atlassian.com/software/views/opensource-community-additional-license-offer">Evaluate Confluence today</a>.<br>
                </p>
                    
        

        <ul id="poweredby">
            <li class="noprint">Powered by <a href="http://www.atlassian.com/software/confluence" class="hover-footer-link" rel="nofollow">Atlassian Confluence</a> <span id='footer-build-information'>7.13.2</span></li>
            <li class="print-only">Printed by Atlassian Confluence 7.13.2</li>
            <li class="noprint"><a href="https://support.atlassian.com/help/confluence" class="hover-footer-link" rel="nofollow">Report a bug</a></li>
            <li class="noprint"><a href="https://www.atlassian.com/company" class="hover-footer-link" rel="nofollow">Atlassian News</a></li>
        </ul>

        

        <div id="footer-logo"><a href="http://www.atlassian.com/" rel="nofollow">Atlassian</a></div>

                    
        
    </section>
</div>

    
</div>

</div><!-- \#full-height-container -->
</div><!-- \#page -->

    <span style="display:none;" id="confluence-server-performance">{"serverDuration": 93, "requestCorrelationId": "df30b4e15b40b6f5"}</span>
</body>

<!-- Mirrored from cwiki.apache.org/confluence/display/Hive/Tutorial by HTTrack Website Copier/3.x [XR&CO'2014], Wed, 15 Dec 2021 19:41:36 GMT -->
</html>
    
